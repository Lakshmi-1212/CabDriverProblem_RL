{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cab-Driver Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-16T15:56:03.090034Z",
     "start_time": "2021-10-16T15:55:59.876892Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "from collections import deque\n",
    "import collections\n",
    "import pickle\n",
    "import os\n",
    "import time\n",
    "\n",
    "\n",
    "# for building DQN model \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# for plotting graphs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import the environment\n",
    "from Env import CabDriver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Time Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-16T15:56:03.096614Z",
     "start_time": "2021-10-16T15:56:03.092767Z"
    }
   },
   "outputs": [],
   "source": [
    "# Loading the time matrix provided\n",
    "Time_matrix = np.load(\"TM.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-16T15:56:03.105670Z",
     "start_time": "2021-10-16T15:56:03.099672Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5, 24, 7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Time_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-16T15:56:03.112633Z",
     "start_time": "2021-10-16T15:56:03.108520Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Time_matrix[1][2][11][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-16T15:56:03.119758Z",
     "start_time": "2021-10-16T15:56:03.114522Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Time_matrix.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maximum time to travel between two locations is 11 hours (next state can change by max of 1 day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tracking the state-action pairs for checking convergence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-16T15:56:03.126309Z",
     "start_time": "2021-10-16T15:56:03.122538Z"
    }
   },
   "outputs": [],
   "source": [
    "#Defining a function to save the Q-dictionary as a pickle file\n",
    "def save_obj(obj, name ):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO  : Picking the architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Architecture 1: input - state, output - q-value for each possible (state, action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-16T04:09:32.582257Z",
     "start_time": "2021-10-16T04:00:12.028Z"
    }
   },
   "source": [
    "Pros:\n",
    "- Model has to be run once for each state  \n",
    "\n",
    "Cons:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T14:21:21.207406Z",
     "start_time": "2021-10-15T14:21:21.194604Z"
    }
   },
   "source": [
    "#### Architecture 2: input - (state, action), output - q-value for the given (state, action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent Class\n",
    "\n",
    "If you are using this framework, you need to fill the following to complete the following code block:\n",
    "1. State and Action Size\n",
    "2. Hyperparameters\n",
    "3. Create a neural-network model in function 'build_model()'\n",
    "4. Define epsilon-greedy strategy in function 'get_action()'\n",
    "5. Complete the function 'append_sample()'. This function appends the recent experience tuple <state, action, reward, new-state> to the memory\n",
    "6. Complete the 'train_model()' function with following logic:\n",
    "   - If the memory size is greater than mini-batch size, you randomly sample experiences from memory as per the mini-batch size and do the following:\n",
    "      - Initialise your input and output batch for training the model\n",
    "      - Calculate the target Q value for each sample: reward + gamma*max(Q(s'a,))\n",
    "      - Get Q(s', a) values from the last trained model\n",
    "      - Update the input batch as your encoded state and output batch as your Q-values\n",
    "      - Then fit your DQN model using the updated input and output batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-16T15:56:03.145491Z",
     "start_time": "2021-10-16T15:56:03.130734Z"
    }
   },
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        # Define size of state and action\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "\n",
    "        # Write here: Specify you hyper parameters for the DQN \n",
    "        self.discount_factor = 0.99\n",
    "        self.learning_rate = 0.001       \n",
    "        self.epsilon_max = 1.0\n",
    "        self.epsilon_decay = 0.999\n",
    "        self.epsilon_min = 0.00000001\n",
    "        self.epsilon = 1\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "        self.explore_count = 0\n",
    "        self.exploit_count = 0\n",
    "        \n",
    "        self.batch_size = 32        \n",
    "        # create replay memory using deque\n",
    "        self.memory = deque(maxlen=2000)\n",
    "\n",
    "        # create main model and target model\n",
    "        self.model = self.build_model()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    # approximate Q function using Neural Network\n",
    "    def build_model(self):\n",
    "        model = Sequential()\n",
    "        \n",
    "        # input layer\n",
    "        model.add(Dense(32, input_dim=self.state_size, activation='relu', kernel_initializer='he_uniform'))\n",
    "        \n",
    "        model.add(Dense(32, activation='relu', kernel_initializer='he_uniform'))\n",
    "        model.add(Dense(32, activation='relu', kernel_initializer='he_uniform')) \n",
    "        \n",
    "        # the output layer: output is of size num_actions\n",
    "        model.add(Dense(self.action_size, activation='relu', kernel_initializer='he_uniform')) \n",
    "        \n",
    "        \n",
    "        \n",
    "        model.compile(loss='mse',optimizer=Adam(lr=self.learning_rate))\n",
    "        model.summary\n",
    "        return model\n",
    "\n",
    "     \n",
    "\n",
    "    def get_action(self, state, episode_count):\n",
    "    # Write your code here:\n",
    "    # get action from model using epsilon-greedy policy\n",
    "    # Decay in ε after we generate each sample from the environment       \n",
    "        \n",
    "        \n",
    "#         exp_value = 1/10**(len(str(episode_count))-1)\n",
    "#         self.epsilon = self.epsilon_min + (self.epsilon_max - self.epsilon_min) * np.exp(-exp_value*episode_count)\n",
    "    \n",
    "        \n",
    "        \n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            # exploration: choose a random action from all possible actions\n",
    "            ##print(f\"{episode_count}: EXPLORE\")\n",
    "            self.explore_count += 1\n",
    "            return random.randrange(self.action_size)\n",
    "\n",
    "        else:\n",
    "            # exploitation: choose the action that returns the maximum q-value\n",
    "            ##print(f\"{episode_count}: EXPLOIT\")\n",
    "            \n",
    "            \n",
    "#             # the first index corresponds to the batch size, so\n",
    "#             # reshape state to (1, state_size) so that the first index corresponds to the batch size \n",
    " \n",
    "            state = np.reshape(state,[1,self.state_size])\n",
    "            q_value = self.model.predict(state) \n",
    "            self.exploit_count += 1\n",
    "            return np.argmax(q_value)\n",
    "         \n",
    " \n",
    "   \n",
    "    def get_summary_details(self):\n",
    "        return self.explore_count, self.exploit_count\n",
    "        \n",
    "\n",
    "        \n",
    "    def reset_episode_counts(self):\n",
    "        self.explore_count = 0\n",
    "        self.exploit_count = 0\n",
    "\n",
    "    def append_sample(self, state, action_idx, reward, next_state, done):\n",
    "    # Write your code here:\n",
    "    # save sample <s,a,r,s',done> to the replay memory after every action\n",
    "        self.memory.append((state, action_idx, reward, next_state, done))\n",
    "        \n",
    "        \n",
    "#         # update ε after each sample\n",
    "#         if self.epsilon > self.epsilon_min:\n",
    "#             self.epsilon *= self.epsilon_decay    \n",
    "    \n",
    "    \n",
    "\n",
    "    # Pick samples randomly from replay memory (with batch_size) and train the network\n",
    "    def train_model(self):\n",
    "        \"\"\"\n",
    "        train the neural network on a minibatch. Input to the network is the states,\n",
    "        output is the target q-value corresponding to each action.\n",
    "        \"\"\"\n",
    "\n",
    "        if len(self.memory) > self.batch_size:\n",
    "            \n",
    "            # sample minibatch from memory\n",
    "            minibatch = random.sample(self.memory, self.batch_size)\n",
    "\n",
    "            # initialise two matrices - update_input and update_output\n",
    "            # Initialise the Q(s,a) with zero\n",
    "            update_input = np.zeros((self.batch_size, self.state_size))\n",
    "            # Initialise the Q(s',a)\n",
    "            update_output = np.zeros((self.batch_size, self.state_size))\n",
    "            actions, rewards, done = [], [], []\n",
    "\n",
    "            # populate update_input and update_output and the lists rewards, actions, done\n",
    "            for i in range(self.batch_size):\n",
    "                state, action_idx, reward, next_state, is_done = minibatch[i]\n",
    "                #print(f'4DEBUG:minibatch[{i}] = {minibatch[i]}')\n",
    "                # Add state s to the Q(s,a), Q(s',a) from memory\n",
    "                update_input[i] = state\n",
    "                # Add action from memory\n",
    "                actions.append(action_idx)\n",
    "                # Add reward from the memory\n",
    "                rewards.append(reward)\n",
    "                # Add next state s' to Q(s',a) from the memory\n",
    "                update_output[i] = next_state\n",
    "                done.append(is_done)\n",
    "\n",
    "            # Find the Q(s,a) and Q(s',a) using state as input to the neural network \n",
    "        \n",
    "            # Predict the target q-values from state s\n",
    "            target = self.model.predict(update_input)\n",
    "\n",
    "            # Get the target for the Q-network\n",
    "            target_qval = self.model.predict(update_output)\n",
    "            \n",
    "            #print(f'4DEBUG: target:{target}')\n",
    "            #print(f'4DEBUG: target_qval:{target_qval}')\n",
    "\n",
    "            # Update the target values - set the target as (r + maxQ(s',a))\n",
    "            for i in range(self.batch_size):\n",
    "                # Q Learning: get maximum Q value at s' from target model\n",
    "                if done[i]:\n",
    "                    target[i][actions[i]] = rewards[i]\n",
    "                else: # non-terminal state\n",
    "                    target[i][actions[i]] = rewards[i] + self.discount_factor * np.max(target_qval[i])\n",
    "\n",
    "            # Train the model\n",
    "            self.model.fit(update_input, target, batch_size=self.batch_size, epochs=1, verbose=0)\n",
    "     \n",
    "\n",
    "\n",
    "    def save_model_weights(self, name):\n",
    "        self.model.save_weights(name)\n",
    "\n",
    "    def save(self, name):\n",
    "        self.model.save(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-16T15:56:03.150550Z",
     "start_time": "2021-10-16T15:56:03.148242Z"
    }
   },
   "outputs": [],
   "source": [
    "Episodes = 1000 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DQN block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-16T15:56:03.256227Z",
     "start_time": "2021-10-16T15:56:03.153949Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State size: 3, Action size: 21\n"
     ]
    }
   ],
   "source": [
    "\n",
    "env = CabDriver()\n",
    "\n",
    "# get size of state and action from environment\n",
    "state_size = len(env.state_space[0])\n",
    "action_size = len(env.action_space)\n",
    "\n",
    "print(f'State size: {state_size}, Action size: {action_size}')\n",
    "\n",
    "# agent needs to be initialised outside the loop since the DQN\n",
    "# network will be initialised along with the agent\n",
    "agent = DQNAgent(action_size=action_size, state_size=state_size) \n",
    "\n",
    "# to store rewards in each episode\n",
    "rewards_per_episode, episodes = [], []\n",
    "\n",
    "# make dir to store model weights\n",
    "if not os.path.exists(\"saved_model_weights\"):\n",
    "    os.mkdir(\"saved_model_weights\")\n",
    " \n",
    "\n",
    "summary_df = pd.DataFrame(columns=['EPISODE','REWARD','MEMORY_LENGTH','EPSILON','EXPLORE_CNT', 'EXPLOIT_CNT', 'EPISODE_TIME'])\n",
    "\n",
    "summary_threshold = 1000\n",
    "def update_summary_details(episode,reward, memory_len, epsilon, explore_count, exploit_count,episode_time):\n",
    "    #print(f'Updating summary details:{match_results}')\n",
    "    return summary_df.append({'EPISODE' : episode,\n",
    "                       'REWARD' : reward,\n",
    "                       'MEMORY_LENGTH' : memory_len,\n",
    "                       'EPSILON' : epsilon,\n",
    "                       'EXPLORE_CNT' : explore_count,\n",
    "                       'EXPLOIT_CNT' : exploit_count,\n",
    "                       'EPISODE_TIME': episode_time\n",
    "                      }, ignore_index=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-16T15:56:03.267373Z",
     "start_time": "2021-10-16T15:56:03.263633Z"
    }
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "for episode in range(Episodes):\n",
    "\n",
    "    # Write code here\n",
    "    # Call the environment\n",
    "    # Call all the initialised variables of the environment\n",
    "    \n",
    "\n",
    "    #Call the DQN agent\n",
    "    \n",
    "    \n",
    "    while !terminal_state:\n",
    "        \n",
    "        # Write your code here\n",
    "        # 1. Pick epsilon-greedy action from possible actions for the current state\n",
    "        # 2. Evaluate your reward and next state\n",
    "        # 3. Append the experience to the memory\n",
    "        # 4. Train the model by calling function agent.train_model\n",
    "        # 5. Keep a track of rewards, Q-values, loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-10-16T15:55:59.929Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 0, reward -180.0, memory_length 116, epsilon 0.999, explore count:116, exploit count:0,time: 7.303\n",
      "Episodes:0 - Elapsed_time:7.305 \n",
      "episode 1, reward -250.0, memory_length 239, epsilon 0.998, explore count:123, exploit count:0,time: 9.515\n",
      "episode 2, reward 54.0, memory_length 351, epsilon 0.997, explore count:111, exploit count:1,time: 7.796\n",
      "episode 3, reward 25.0, memory_length 481, epsilon 0.99601, explore count:130, exploit count:0,time: 10.407\n",
      "episode 4, reward -201.0, memory_length 600, epsilon 0.99501, explore count:119, exploit count:0,time: 8.677\n",
      "episode 5, reward 27.0, memory_length 708, epsilon 0.99401, explore count:107, exploit count:1,time: 7.504\n",
      "episode 6, reward 134.0, memory_length 835, epsilon 0.99302, explore count:125, exploit count:2,time: 8.957\n",
      "episode 7, reward 258.0, memory_length 950, epsilon 0.99203, explore count:115, exploit count:0,time: 8.05\n",
      "episode 8, reward -185.0, memory_length 1062, epsilon 0.99104, explore count:112, exploit count:0,time: 7.668\n",
      "episode 9, reward -75.0, memory_length 1195, epsilon 0.99004, explore count:131, exploit count:2,time: 9.311\n",
      "episode 10, reward -163.0, memory_length 1316, epsilon 0.98905, explore count:119, exploit count:2,time: 8.59\n",
      "episode 11, reward 237.0, memory_length 1442, epsilon 0.98807, explore count:124, exploit count:2,time: 8.716\n",
      "episode 12, reward 121.0, memory_length 1566, epsilon 0.98708, explore count:123, exploit count:1,time: 8.645\n",
      "episode 13, reward -219.0, memory_length 1680, epsilon 0.98609, explore count:111, exploit count:3,time: 7.927\n",
      "episode 14, reward 158.0, memory_length 1785, epsilon 0.9851, explore count:104, exploit count:1,time: 7.339\n",
      "episode 15, reward -22.0, memory_length 1895, epsilon 0.98412, explore count:109, exploit count:1,time: 7.763\n",
      "episode 16, reward -269.0, memory_length 2000, epsilon 0.98314, explore count:108, exploit count:1,time: 7.511\n",
      "episode 17, reward 112.0, memory_length 2000, epsilon 0.98215, explore count:107, exploit count:2,time: 7.712\n",
      "episode 18, reward -225.0, memory_length 2000, epsilon 0.98117, explore count:108, exploit count:0,time: 7.395\n",
      "episode 19, reward 70.0, memory_length 2000, epsilon 0.98019, explore count:118, exploit count:3,time: 8.574\n",
      "episode 20, reward 40.0, memory_length 2000, epsilon 0.97921, explore count:112, exploit count:3,time: 8.124\n",
      "episode 21, reward -190.0, memory_length 2000, epsilon 0.97823, explore count:111, exploit count:1,time: 8.692\n",
      "episode 22, reward -230.0, memory_length 2000, epsilon 0.97725, explore count:113, exploit count:4,time: 9.245\n",
      "episode 23, reward 206.0, memory_length 2000, epsilon 0.97627, explore count:110, exploit count:2,time: 8.414\n",
      "episode 24, reward -167.0, memory_length 2000, epsilon 0.9753, explore count:105, exploit count:3,time: 8.111\n",
      "episode 25, reward 134.0, memory_length 2000, epsilon 0.97432, explore count:112, exploit count:1,time: 8.12\n",
      "episode 26, reward 95.0, memory_length 2000, epsilon 0.97335, explore count:112, exploit count:2,time: 7.946\n",
      "episode 27, reward -301.0, memory_length 2000, epsilon 0.97237, explore count:113, exploit count:5,time: 8.439\n",
      "episode 28, reward -162.0, memory_length 2000, epsilon 0.9714, explore count:114, exploit count:2,time: 8.111\n",
      "episode 29, reward -104.0, memory_length 2000, epsilon 0.97043, explore count:127, exploit count:3,time: 9.214\n",
      "episode 30, reward 130.0, memory_length 2000, epsilon 0.96946, explore count:117, exploit count:6,time: 8.845\n",
      "episode 31, reward 0.0, memory_length 2000, epsilon 0.96849, explore count:117, exploit count:4,time: 8.474\n",
      "episode 32, reward -94.0, memory_length 2000, epsilon 0.96752, explore count:113, exploit count:4,time: 8.326\n",
      "episode 33, reward -32.0, memory_length 2000, epsilon 0.96656, explore count:121, exploit count:5,time: 8.932\n",
      "episode 34, reward -149.0, memory_length 2000, epsilon 0.96559, explore count:108, exploit count:6,time: 8.091\n",
      "episode 35, reward -137.0, memory_length 2000, epsilon 0.96462, explore count:105, exploit count:4,time: 7.799\n",
      "episode 36, reward -14.0, memory_length 2000, epsilon 0.96366, explore count:110, exploit count:0,time: 7.619\n",
      "episode 37, reward -172.0, memory_length 2000, epsilon 0.96269, explore count:126, exploit count:3,time: 9.341\n",
      "episode 38, reward -293.0, memory_length 2000, epsilon 0.96173, explore count:106, exploit count:4,time: 8.08\n",
      "episode 39, reward 43.0, memory_length 2000, epsilon 0.96077, explore count:97, exploit count:5,time: 7.841\n",
      "episode 40, reward 228.0, memory_length 2000, epsilon 0.95981, explore count:116, exploit count:5,time: 9.214\n",
      "episode 41, reward -163.0, memory_length 2000, epsilon 0.95885, explore count:122, exploit count:2,time: 9.187\n",
      "episode 42, reward 4.0, memory_length 2000, epsilon 0.95789, explore count:118, exploit count:3,time: 8.611\n",
      "episode 43, reward 163.0, memory_length 2000, epsilon 0.95693, explore count:132, exploit count:6,time: 10.058\n",
      "episode 44, reward -118.0, memory_length 2000, epsilon 0.95598, explore count:103, exploit count:8,time: 8.243\n",
      "episode 45, reward -171.0, memory_length 2000, epsilon 0.95502, explore count:115, exploit count:9,time: 8.862\n",
      "episode 46, reward 112.0, memory_length 2000, epsilon 0.95406, explore count:111, exploit count:9,time: 8.844\n",
      "episode 47, reward 139.0, memory_length 2000, epsilon 0.95311, explore count:121, exploit count:13,time: 10.355\n",
      "episode 48, reward 55.0, memory_length 2000, epsilon 0.95216, explore count:109, exploit count:5,time: 8.455\n",
      "episode 49, reward -199.0, memory_length 2000, epsilon 0.95121, explore count:107, exploit count:3,time: 8.496\n",
      "episode 50, reward -177.0, memory_length 2000, epsilon 0.95025, explore count:112, exploit count:8,time: 10.454\n",
      "episode 51, reward -194.0, memory_length 2000, epsilon 0.9493, explore count:124, exploit count:4,time: 9.466\n",
      "episode 52, reward 40.0, memory_length 2000, epsilon 0.94835, explore count:110, exploit count:6,time: 9.201\n",
      "episode 53, reward -324.0, memory_length 2000, epsilon 0.94741, explore count:107, exploit count:8,time: 9.11\n",
      "episode 54, reward -266.0, memory_length 2000, epsilon 0.94646, explore count:122, exploit count:9,time: 10.171\n",
      "episode 55, reward -72.0, memory_length 2000, epsilon 0.94551, explore count:108, exploit count:6,time: 9.086\n",
      "episode 56, reward 101.0, memory_length 2000, epsilon 0.94457, explore count:112, exploit count:5,time: 8.946\n",
      "episode 57, reward -117.0, memory_length 2000, epsilon 0.94362, explore count:120, exploit count:10,time: 11.009\n",
      "episode 58, reward 274.0, memory_length 2000, epsilon 0.94268, explore count:118, exploit count:5,time: 10.651\n",
      "episode 59, reward -147.0, memory_length 2000, epsilon 0.94174, explore count:121, exploit count:11,time: 10.569\n",
      "episode 60, reward 58.0, memory_length 2000, epsilon 0.94079, explore count:111, exploit count:7,time: 9.338\n",
      "episode 61, reward -262.0, memory_length 2000, epsilon 0.93985, explore count:103, exploit count:10,time: 9.047\n",
      "episode 62, reward -79.0, memory_length 2000, epsilon 0.93891, explore count:107, exploit count:9,time: 9.229\n",
      "episode 63, reward -132.0, memory_length 2000, epsilon 0.93797, explore count:110, exploit count:7,time: 8.804\n",
      "episode 64, reward 108.0, memory_length 2000, epsilon 0.93704, explore count:104, exploit count:11,time: 9.803\n",
      "episode 65, reward -181.0, memory_length 2000, epsilon 0.9361, explore count:114, exploit count:6,time: 9.231\n",
      "episode 66, reward -210.0, memory_length 2000, epsilon 0.93516, explore count:106, exploit count:9,time: 9.335\n",
      "episode 67, reward -74.0, memory_length 2000, epsilon 0.93423, explore count:113, exploit count:2,time: 8.544\n",
      "episode 68, reward -63.0, memory_length 2000, epsilon 0.93329, explore count:117, exploit count:5,time: 9.273\n",
      "episode 69, reward 225.0, memory_length 2000, epsilon 0.93236, explore count:111, exploit count:6,time: 9.351\n",
      "episode 70, reward 76.0, memory_length 2000, epsilon 0.93143, explore count:122, exploit count:9,time: 10.345\n",
      "episode 71, reward -95.0, memory_length 2000, epsilon 0.9305, explore count:100, exploit count:8,time: 8.321\n",
      "episode 72, reward -104.0, memory_length 2000, epsilon 0.92957, explore count:112, exploit count:5,time: 8.423\n",
      "episode 73, reward 18.0, memory_length 2000, epsilon 0.92864, explore count:126, exploit count:11,time: 9.948\n",
      "episode 74, reward 99.0, memory_length 2000, epsilon 0.92771, explore count:115, exploit count:9,time: 9.988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 75, reward 132.0, memory_length 2000, epsilon 0.92678, explore count:103, exploit count:6,time: 8.61\n",
      "episode 76, reward -27.0, memory_length 2000, epsilon 0.92585, explore count:113, exploit count:8,time: 8.743\n",
      "episode 77, reward 54.0, memory_length 2000, epsilon 0.92493, explore count:110, exploit count:14,time: 9.763\n",
      "episode 78, reward -77.0, memory_length 2000, epsilon 0.924, explore count:99, exploit count:12,time: 9.831\n",
      "episode 79, reward -104.0, memory_length 2000, epsilon 0.92308, explore count:111, exploit count:7,time: 8.44\n",
      "episode 80, reward -36.0, memory_length 2000, epsilon 0.92216, explore count:111, exploit count:10,time: 10.37\n",
      "episode 81, reward 75.0, memory_length 2000, epsilon 0.92123, explore count:104, exploit count:8,time: 8.841\n",
      "episode 82, reward -42.0, memory_length 2000, epsilon 0.92031, explore count:113, exploit count:8,time: 9.372\n",
      "episode 83, reward 79.0, memory_length 2000, epsilon 0.91939, explore count:117, exploit count:13,time: 10.91\n",
      "episode 84, reward -172.0, memory_length 2000, epsilon 0.91847, explore count:122, exploit count:6,time: 10.498\n",
      "episode 85, reward -92.0, memory_length 2000, epsilon 0.91755, explore count:99, exploit count:12,time: 8.57\n",
      "episode 86, reward -27.0, memory_length 2000, epsilon 0.91664, explore count:117, exploit count:9,time: 10.008\n",
      "episode 87, reward -14.0, memory_length 2000, epsilon 0.91572, explore count:108, exploit count:10,time: 9.229\n",
      "episode 88, reward -104.0, memory_length 2000, epsilon 0.9148, explore count:112, exploit count:7,time: 9.291\n",
      "episode 89, reward 88.0, memory_length 2000, epsilon 0.91389, explore count:118, exploit count:7,time: 9.991\n",
      "episode 90, reward -397.0, memory_length 2000, epsilon 0.91298, explore count:106, exploit count:12,time: 9.042\n",
      "episode 91, reward -254.0, memory_length 2000, epsilon 0.91206, explore count:105, exploit count:10,time: 8.22\n",
      "episode 92, reward 13.0, memory_length 2000, epsilon 0.91115, explore count:102, exploit count:12,time: 8.304\n",
      "episode 93, reward 130.0, memory_length 2000, epsilon 0.91024, explore count:125, exploit count:11,time: 9.77\n",
      "episode 94, reward 125.0, memory_length 2000, epsilon 0.90933, explore count:111, exploit count:7,time: 8.286\n",
      "episode 95, reward -145.0, memory_length 2000, epsilon 0.90842, explore count:116, exploit count:8,time: 8.871\n",
      "episode 96, reward -59.0, memory_length 2000, epsilon 0.90751, explore count:133, exploit count:16,time: 10.798\n",
      "episode 97, reward -177.0, memory_length 2000, epsilon 0.9066, explore count:114, exploit count:11,time: 8.954\n",
      "episode 98, reward -113.0, memory_length 2000, epsilon 0.9057, explore count:99, exploit count:10,time: 7.975\n",
      "episode 99, reward 88.0, memory_length 2000, epsilon 0.90479, explore count:108, exploit count:13,time: 8.869\n",
      "episode 100, reward -356.0, memory_length 2000, epsilon 0.90389, explore count:103, exploit count:15,time: 8.554\n",
      "episode 101, reward -63.0, memory_length 2000, epsilon 0.90298, explore count:114, exploit count:18,time: 9.663\n",
      "episode 102, reward -180.0, memory_length 2000, epsilon 0.90208, explore count:95, exploit count:20,time: 8.595\n",
      "episode 103, reward -403.0, memory_length 2000, epsilon 0.90118, explore count:95, exploit count:9,time: 7.383\n",
      "episode 104, reward -59.0, memory_length 2000, epsilon 0.90028, explore count:109, exploit count:12,time: 8.845\n",
      "episode 105, reward -1.0, memory_length 2000, epsilon 0.89938, explore count:109, exploit count:15,time: 9.025\n",
      "episode 106, reward -160.0, memory_length 2000, epsilon 0.89848, explore count:115, exploit count:16,time: 9.401\n",
      "episode 107, reward -349.0, memory_length 2000, epsilon 0.89758, explore count:112, exploit count:13,time: 9.035\n",
      "episode 108, reward 71.0, memory_length 2000, epsilon 0.89668, explore count:110, exploit count:14,time: 9.025\n",
      "episode 109, reward -176.0, memory_length 2000, epsilon 0.89578, explore count:99, exploit count:12,time: 7.963\n",
      "episode 110, reward -230.0, memory_length 2000, epsilon 0.89489, explore count:113, exploit count:14,time: 9.196\n",
      "episode 111, reward -113.0, memory_length 2000, epsilon 0.89399, explore count:105, exploit count:11,time: 8.404\n",
      "episode 112, reward -23.0, memory_length 2000, epsilon 0.8931, explore count:112, exploit count:17,time: 9.262\n",
      "episode 113, reward 102.0, memory_length 2000, epsilon 0.89221, explore count:130, exploit count:15,time: 10.435\n",
      "episode 114, reward -131.0, memory_length 2000, epsilon 0.89131, explore count:105, exploit count:14,time: 8.649\n",
      "episode 115, reward -40.0, memory_length 2000, epsilon 0.89042, explore count:109, exploit count:24,time: 10.079\n",
      "episode 116, reward -189.0, memory_length 2000, epsilon 0.88953, explore count:99, exploit count:13,time: 8.049\n",
      "episode 117, reward -219.0, memory_length 2000, epsilon 0.88864, explore count:103, exploit count:13,time: 8.501\n",
      "episode 118, reward -41.0, memory_length 2000, epsilon 0.88775, explore count:109, exploit count:15,time: 9.084\n",
      "episode 119, reward -117.0, memory_length 2000, epsilon 0.88687, explore count:99, exploit count:20,time: 8.697\n",
      "episode 120, reward -531.0, memory_length 2000, epsilon 0.88598, explore count:97, exploit count:13,time: 8.036\n",
      "episode 121, reward -50.0, memory_length 2000, epsilon 0.88509, explore count:109, exploit count:13,time: 8.85\n",
      "episode 122, reward 418.0, memory_length 2000, epsilon 0.88421, explore count:119, exploit count:13,time: 9.426\n",
      "episode 123, reward 12.0, memory_length 2000, epsilon 0.88333, explore count:100, exploit count:12,time: 8.133\n",
      "episode 124, reward -351.0, memory_length 2000, epsilon 0.88244, explore count:117, exploit count:19,time: 9.985\n",
      "episode 125, reward -189.0, memory_length 2000, epsilon 0.88156, explore count:115, exploit count:14,time: 9.249\n",
      "episode 126, reward -286.0, memory_length 2000, epsilon 0.88068, explore count:109, exploit count:15,time: 9.045\n",
      "episode 127, reward -406.0, memory_length 2000, epsilon 0.8798, explore count:113, exploit count:13,time: 9.101\n",
      "episode 128, reward -122.0, memory_length 2000, epsilon 0.87892, explore count:100, exploit count:25,time: 9.221\n",
      "episode 129, reward 62.0, memory_length 2000, epsilon 0.87804, explore count:106, exploit count:22,time: 9.507\n",
      "episode 130, reward 13.0, memory_length 2000, epsilon 0.87716, explore count:113, exploit count:18,time: 9.636\n",
      "episode 131, reward -184.0, memory_length 2000, epsilon 0.87628, explore count:113, exploit count:16,time: 9.5\n",
      "episode 132, reward 126.0, memory_length 2000, epsilon 0.87541, explore count:112, exploit count:11,time: 8.829\n",
      "episode 133, reward -45.0, memory_length 2000, epsilon 0.87453, explore count:100, exploit count:11,time: 8.01\n",
      "episode 134, reward -174.0, memory_length 2000, epsilon 0.87366, explore count:105, exploit count:13,time: 8.517\n",
      "episode 135, reward -423.0, memory_length 2000, epsilon 0.87278, explore count:105, exploit count:15,time: 8.638\n",
      "episode 136, reward -254.0, memory_length 2000, epsilon 0.87191, explore count:114, exploit count:16,time: 9.51\n",
      "episode 137, reward -320.0, memory_length 2000, epsilon 0.87104, explore count:111, exploit count:23,time: 9.94\n",
      "episode 138, reward -46.0, memory_length 2000, epsilon 0.87017, explore count:121, exploit count:18,time: 10.047\n",
      "episode 139, reward 139.0, memory_length 2000, epsilon 0.8693, explore count:112, exploit count:16,time: 9.343\n",
      "episode 140, reward 73.0, memory_length 2000, epsilon 0.86843, explore count:111, exploit count:16,time: 9.301\n",
      "episode 141, reward 117.0, memory_length 2000, epsilon 0.86756, explore count:101, exploit count:20,time: 8.936\n",
      "episode 142, reward -144.0, memory_length 2000, epsilon 0.86669, explore count:111, exploit count:19,time: 9.437\n",
      "episode 143, reward -18.0, memory_length 2000, epsilon 0.86583, explore count:108, exploit count:15,time: 9.008\n",
      "episode 144, reward -92.0, memory_length 2000, epsilon 0.86496, explore count:112, exploit count:15,time: 9.289\n",
      "episode 145, reward -105.0, memory_length 2000, epsilon 0.86409, explore count:99, exploit count:22,time: 8.921\n",
      "episode 146, reward -334.0, memory_length 2000, epsilon 0.86323, explore count:114, exploit count:23,time: 10.147\n",
      "episode 147, reward 70.0, memory_length 2000, epsilon 0.86237, explore count:114, exploit count:12,time: 9.083\n",
      "episode 148, reward 65.0, memory_length 2000, epsilon 0.8615, explore count:93, exploit count:15,time: 7.829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 149, reward -282.0, memory_length 2000, epsilon 0.86064, explore count:98, exploit count:22,time: 8.952\n",
      "episode 150, reward 135.0, memory_length 2000, epsilon 0.85978, explore count:100, exploit count:21,time: 8.998\n",
      "episode 151, reward -273.0, memory_length 2000, epsilon 0.85892, explore count:104, exploit count:20,time: 9.178\n",
      "episode 152, reward 426.0, memory_length 2000, epsilon 0.85806, explore count:107, exploit count:13,time: 8.55\n",
      "episode 153, reward -233.0, memory_length 2000, epsilon 0.85721, explore count:109, exploit count:7,time: 8.17\n",
      "episode 154, reward -5.0, memory_length 2000, epsilon 0.85635, explore count:100, exploit count:11,time: 7.798\n",
      "episode 155, reward -267.0, memory_length 2000, epsilon 0.85549, explore count:106, exploit count:19,time: 9.145\n",
      "episode 156, reward 36.0, memory_length 2000, epsilon 0.85464, explore count:108, exploit count:14,time: 8.861\n",
      "episode 157, reward -32.0, memory_length 2000, epsilon 0.85378, explore count:105, exploit count:16,time: 8.954\n",
      "episode 158, reward -88.0, memory_length 2000, epsilon 0.85293, explore count:115, exploit count:13,time: 9.218\n",
      "episode 159, reward -59.0, memory_length 2000, epsilon 0.85208, explore count:103, exploit count:14,time: 8.582\n",
      "episode 160, reward -172.0, memory_length 2000, epsilon 0.85122, explore count:104, exploit count:17,time: 8.869\n",
      "episode 161, reward -245.0, memory_length 2000, epsilon 0.85037, explore count:103, exploit count:24,time: 9.312\n",
      "episode 162, reward -131.0, memory_length 2000, epsilon 0.84952, explore count:97, exploit count:24,time: 9.055\n",
      "episode 163, reward -216.0, memory_length 2000, epsilon 0.84867, explore count:107, exploit count:21,time: 9.463\n",
      "episode 164, reward -195.0, memory_length 2000, epsilon 0.84782, explore count:109, exploit count:15,time: 8.886\n",
      "episode 165, reward -218.0, memory_length 2000, epsilon 0.84698, explore count:102, exploit count:24,time: 9.386\n",
      "episode 166, reward -5.0, memory_length 2000, epsilon 0.84613, explore count:106, exploit count:21,time: 9.391\n",
      "episode 167, reward -226.0, memory_length 2000, epsilon 0.84528, explore count:109, exploit count:18,time: 9.296\n",
      "episode 168, reward -91.0, memory_length 2000, epsilon 0.84444, explore count:104, exploit count:24,time: 9.387\n",
      "episode 169, reward -209.0, memory_length 2000, epsilon 0.84359, explore count:121, exploit count:14,time: 9.796\n",
      "episode 170, reward 31.0, memory_length 2000, epsilon 0.84275, explore count:115, exploit count:12,time: 9.256\n",
      "episode 171, reward -343.0, memory_length 2000, epsilon 0.84191, explore count:96, exploit count:20,time: 8.494\n",
      "episode 172, reward -41.0, memory_length 2000, epsilon 0.84106, explore count:94, exploit count:26,time: 9.048\n",
      "episode 173, reward -50.0, memory_length 2000, epsilon 0.84022, explore count:107, exploit count:17,time: 9.095\n",
      "episode 174, reward -154.0, memory_length 2000, epsilon 0.83938, explore count:103, exploit count:20,time: 8.966\n",
      "episode 175, reward -126.0, memory_length 2000, epsilon 0.83854, explore count:91, exploit count:14,time: 7.733\n",
      "episode 176, reward -263.0, memory_length 2000, epsilon 0.83771, explore count:104, exploit count:23,time: 9.486\n",
      "episode 177, reward -69.0, memory_length 2000, epsilon 0.83687, explore count:114, exploit count:14,time: 9.232\n",
      "episode 178, reward -135.0, memory_length 2000, epsilon 0.83603, explore count:95, exploit count:26,time: 9.116\n",
      "episode 179, reward 36.0, memory_length 2000, epsilon 0.83519, explore count:115, exploit count:27,time: 10.589\n",
      "episode 180, reward -72.0, memory_length 2000, epsilon 0.83436, explore count:103, exploit count:23,time: 9.375\n",
      "episode 181, reward -23.0, memory_length 2000, epsilon 0.83353, explore count:107, exploit count:19,time: 9.169\n",
      "episode 182, reward -104.0, memory_length 2000, epsilon 0.83269, explore count:97, exploit count:23,time: 8.97\n",
      "episode 183, reward -246.0, memory_length 2000, epsilon 0.83186, explore count:106, exploit count:13,time: 8.706\n",
      "episode 184, reward -131.0, memory_length 2000, epsilon 0.83103, explore count:103, exploit count:26,time: 9.554\n",
      "episode 185, reward -136.0, memory_length 2000, epsilon 0.8302, explore count:101, exploit count:30,time: 9.955\n",
      "episode 186, reward -95.0, memory_length 2000, epsilon 0.82937, explore count:107, exploit count:24,time: 9.74\n",
      "episode 187, reward -180.0, memory_length 2000, epsilon 0.82854, explore count:102, exploit count:17,time: 8.738\n",
      "episode 188, reward -361.0, memory_length 2000, epsilon 0.82771, explore count:105, exploit count:27,time: 9.774\n",
      "episode 189, reward -419.0, memory_length 2000, epsilon 0.82688, explore count:111, exploit count:21,time: 9.73\n",
      "episode 190, reward -145.0, memory_length 2000, epsilon 0.82605, explore count:116, exploit count:17,time: 9.699\n",
      "episode 191, reward -153.0, memory_length 2000, epsilon 0.82523, explore count:99, exploit count:24,time: 9.221\n",
      "episode 192, reward 75.0, memory_length 2000, epsilon 0.8244, explore count:104, exploit count:20,time: 9.03\n",
      "episode 193, reward -113.0, memory_length 2000, epsilon 0.82358, explore count:102, exploit count:24,time: 9.38\n",
      "episode 194, reward -252.0, memory_length 2000, epsilon 0.82275, explore count:107, exploit count:26,time: 9.948\n",
      "episode 195, reward -250.0, memory_length 2000, epsilon 0.82193, explore count:102, exploit count:19,time: 8.875\n",
      "episode 196, reward -95.0, memory_length 2000, epsilon 0.82111, explore count:98, exploit count:29,time: 9.659\n",
      "episode 197, reward -26.0, memory_length 2000, epsilon 0.82029, explore count:105, exploit count:24,time: 9.632\n",
      "episode 198, reward -147.0, memory_length 2000, epsilon 0.81947, explore count:102, exploit count:26,time: 9.692\n",
      "episode 199, reward -108.0, memory_length 2000, epsilon 0.81865, explore count:95, exploit count:21,time: 8.504\n",
      "episode 200, reward -37.0, memory_length 2000, epsilon 0.81783, explore count:95, exploit count:26,time: 9.109\n",
      "episode 201, reward -419.0, memory_length 2000, epsilon 0.81701, explore count:98, exploit count:23,time: 9.046\n",
      "episode 202, reward -216.0, memory_length 2000, epsilon 0.8162, explore count:101, exploit count:14,time: 8.264\n",
      "episode 203, reward -24.0, memory_length 2000, epsilon 0.81538, explore count:100, exploit count:27,time: 9.548\n",
      "episode 204, reward -167.0, memory_length 2000, epsilon 0.81456, explore count:109, exploit count:21,time: 9.599\n",
      "episode 205, reward -194.0, memory_length 2000, epsilon 0.81375, explore count:105, exploit count:19,time: 9.022\n",
      "episode 206, reward -171.0, memory_length 2000, epsilon 0.81294, explore count:98, exploit count:19,time: 8.653\n",
      "episode 207, reward -36.0, memory_length 2000, epsilon 0.81212, explore count:114, exploit count:21,time: 10.011\n",
      "episode 208, reward -176.0, memory_length 2000, epsilon 0.81131, explore count:104, exploit count:25,time: 9.668\n",
      "episode 209, reward -133.0, memory_length 2000, epsilon 0.8105, explore count:109, exploit count:15,time: 8.965\n",
      "episode 210, reward 13.0, memory_length 2000, epsilon 0.80969, explore count:104, exploit count:26,time: 9.742\n",
      "episode 211, reward 24.0, memory_length 2000, epsilon 0.80888, explore count:96, exploit count:27,time: 9.1\n",
      "episode 212, reward -149.0, memory_length 2000, epsilon 0.80807, explore count:102, exploit count:31,time: 9.967\n",
      "episode 213, reward -189.0, memory_length 2000, epsilon 0.80726, explore count:110, exploit count:20,time: 9.616\n",
      "episode 214, reward -140.0, memory_length 2000, epsilon 0.80645, explore count:105, exploit count:25,time: 9.896\n",
      "episode 215, reward 57.0, memory_length 2000, epsilon 0.80565, explore count:122, exploit count:25,time: 12.242\n",
      "episode 216, reward -78.0, memory_length 2000, epsilon 0.80484, explore count:95, exploit count:30,time: 10.595\n",
      "episode 217, reward -54.0, memory_length 2000, epsilon 0.80404, explore count:116, exploit count:18,time: 9.933\n",
      "episode 218, reward 153.0, memory_length 2000, epsilon 0.80323, explore count:101, exploit count:24,time: 9.336\n",
      "episode 219, reward -459.0, memory_length 2000, epsilon 0.80243, explore count:102, exploit count:22,time: 9.226\n",
      "episode 220, reward -236.0, memory_length 2000, epsilon 0.80163, explore count:104, exploit count:28,time: 9.78\n",
      "episode 221, reward -369.0, memory_length 2000, epsilon 0.80083, explore count:103, exploit count:26,time: 9.958\n",
      "episode 222, reward -316.0, memory_length 2000, epsilon 0.80003, explore count:101, exploit count:30,time: 10.028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 223, reward -306.0, memory_length 2000, epsilon 0.79923, explore count:96, exploit count:19,time: 8.571\n",
      "episode 224, reward 108.0, memory_length 2000, epsilon 0.79843, explore count:96, exploit count:33,time: 9.657\n",
      "episode 225, reward -44.0, memory_length 2000, epsilon 0.79763, explore count:97, exploit count:22,time: 8.885\n",
      "episode 226, reward -140.0, memory_length 2000, epsilon 0.79683, explore count:99, exploit count:32,time: 9.964\n",
      "episode 227, reward -311.0, memory_length 2000, epsilon 0.79603, explore count:92, exploit count:27,time: 9.039\n",
      "episode 228, reward -81.0, memory_length 2000, epsilon 0.79524, explore count:91, exploit count:21,time: 8.181\n",
      "episode 229, reward -365.0, memory_length 2000, epsilon 0.79444, explore count:96, exploit count:19,time: 8.541\n",
      "episode 230, reward -284.0, memory_length 2000, epsilon 0.79365, explore count:89, exploit count:30,time: 9.131\n",
      "episode 231, reward -90.0, memory_length 2000, epsilon 0.79285, explore count:92, exploit count:25,time: 8.711\n",
      "episode 232, reward -34.0, memory_length 2000, epsilon 0.79206, explore count:107, exploit count:29,time: 10.304\n",
      "episode 233, reward -342.0, memory_length 2000, epsilon 0.79127, explore count:95, exploit count:28,time: 9.358\n",
      "episode 234, reward -239.0, memory_length 2000, epsilon 0.79048, explore count:103, exploit count:33,time: 10.444\n",
      "episode 235, reward -113.0, memory_length 2000, epsilon 0.78969, explore count:95, exploit count:24,time: 8.78\n",
      "episode 236, reward -176.0, memory_length 2000, epsilon 0.7889, explore count:92, exploit count:27,time: 9.015\n",
      "episode 237, reward -144.0, memory_length 2000, epsilon 0.78811, explore count:101, exploit count:27,time: 9.588\n",
      "episode 238, reward -349.0, memory_length 2000, epsilon 0.78732, explore count:99, exploit count:29,time: 9.573\n",
      "episode 239, reward -39.0, memory_length 2000, epsilon 0.78653, explore count:100, exploit count:23,time: 9.218\n",
      "episode 240, reward -325.0, memory_length 2000, epsilon 0.78575, explore count:93, exploit count:25,time: 8.898\n",
      "episode 241, reward -126.0, memory_length 2000, epsilon 0.78496, explore count:100, exploit count:40,time: 10.787\n",
      "episode 242, reward -329.0, memory_length 2000, epsilon 0.78418, explore count:96, exploit count:32,time: 9.631\n",
      "episode 243, reward 252.0, memory_length 2000, epsilon 0.78339, explore count:99, exploit count:25,time: 9.308\n",
      "episode 244, reward 2.0, memory_length 2000, epsilon 0.78261, explore count:106, exploit count:31,time: 10.443\n",
      "episode 245, reward -423.0, memory_length 2000, epsilon 0.78183, explore count:102, exploit count:17,time: 8.752\n",
      "episode 246, reward -203.0, memory_length 2000, epsilon 0.78104, explore count:107, exploit count:24,time: 9.831\n",
      "episode 247, reward -70.0, memory_length 2000, epsilon 0.78026, explore count:88, exploit count:26,time: 8.611\n",
      "episode 248, reward -456.0, memory_length 2000, epsilon 0.77948, explore count:90, exploit count:31,time: 9.238\n",
      "episode 249, reward 117.0, memory_length 2000, epsilon 0.7787, explore count:100, exploit count:29,time: 9.645\n",
      "episode 250, reward -205.0, memory_length 2000, epsilon 0.77792, explore count:101, exploit count:23,time: 9.251\n",
      "episode 251, reward -53.0, memory_length 2000, epsilon 0.77715, explore count:104, exploit count:24,time: 9.619\n",
      "episode 252, reward -217.0, memory_length 2000, epsilon 0.77637, explore count:95, exploit count:28,time: 9.208\n",
      "episode 253, reward -73.0, memory_length 2000, epsilon 0.77559, explore count:107, exploit count:34,time: 10.706\n",
      "episode 254, reward -73.0, memory_length 2000, epsilon 0.77482, explore count:100, exploit count:24,time: 9.257\n",
      "episode 255, reward -222.0, memory_length 2000, epsilon 0.77404, explore count:109, exploit count:22,time: 9.73\n",
      "episode 256, reward -146.0, memory_length 2000, epsilon 0.77327, explore count:103, exploit count:23,time: 9.281\n",
      "episode 257, reward 90.0, memory_length 2000, epsilon 0.7725, explore count:105, exploit count:26,time: 9.866\n",
      "episode 258, reward -41.0, memory_length 2000, epsilon 0.77172, explore count:98, exploit count:29,time: 9.618\n",
      "episode 259, reward -77.0, memory_length 2000, epsilon 0.77095, explore count:102, exploit count:35,time: 10.498\n",
      "episode 260, reward 74.0, memory_length 2000, epsilon 0.77018, explore count:103, exploit count:26,time: 9.52\n",
      "episode 261, reward 37.0, memory_length 2000, epsilon 0.76941, explore count:92, exploit count:29,time: 9.226\n",
      "episode 262, reward 27.0, memory_length 2000, epsilon 0.76864, explore count:106, exploit count:32,time: 10.431\n",
      "episode 263, reward -329.0, memory_length 2000, epsilon 0.76787, explore count:96, exploit count:33,time: 9.972\n",
      "episode 264, reward -288.0, memory_length 2000, epsilon 0.7671, explore count:94, exploit count:36,time: 9.918\n",
      "episode 265, reward -51.0, memory_length 2000, epsilon 0.76634, explore count:100, exploit count:34,time: 10.263\n",
      "episode 266, reward -329.0, memory_length 2000, epsilon 0.76557, explore count:99, exploit count:30,time: 9.777\n",
      "episode 267, reward -384.0, memory_length 2000, epsilon 0.76481, explore count:98, exploit count:26,time: 9.243\n",
      "episode 268, reward -69.0, memory_length 2000, epsilon 0.76404, explore count:90, exploit count:30,time: 9.05\n",
      "episode 269, reward -333.0, memory_length 2000, epsilon 0.76328, explore count:92, exploit count:27,time: 8.989\n",
      "episode 270, reward -258.0, memory_length 2000, epsilon 0.76251, explore count:105, exploit count:29,time: 10.131\n",
      "episode 271, reward -222.0, memory_length 2000, epsilon 0.76175, explore count:95, exploit count:31,time: 9.67\n",
      "episode 272, reward -81.0, memory_length 2000, epsilon 0.76099, explore count:86, exploit count:34,time: 9.13\n",
      "episode 273, reward -117.0, memory_length 2000, epsilon 0.76023, explore count:100, exploit count:36,time: 10.456\n",
      "episode 274, reward -1.0, memory_length 2000, epsilon 0.75947, explore count:106, exploit count:24,time: 9.723\n",
      "episode 275, reward -270.0, memory_length 2000, epsilon 0.75871, explore count:101, exploit count:24,time: 9.318\n",
      "episode 276, reward -208.0, memory_length 2000, epsilon 0.75795, explore count:100, exploit count:20,time: 8.812\n",
      "episode 277, reward -293.0, memory_length 2000, epsilon 0.75719, explore count:104, exploit count:28,time: 9.957\n",
      "episode 278, reward -121.0, memory_length 2000, epsilon 0.75643, explore count:92, exploit count:34,time: 9.569\n",
      "episode 279, reward -313.0, memory_length 2000, epsilon 0.75568, explore count:91, exploit count:36,time: 9.689\n",
      "episode 280, reward -176.0, memory_length 2000, epsilon 0.75492, explore count:104, exploit count:37,time: 10.681\n",
      "episode 281, reward -347.0, memory_length 2000, epsilon 0.75417, explore count:96, exploit count:35,time: 10.028\n",
      "episode 282, reward -264.0, memory_length 2000, epsilon 0.75341, explore count:103, exploit count:27,time: 9.815\n",
      "episode 283, reward -275.0, memory_length 2000, epsilon 0.75266, explore count:92, exploit count:35,time: 9.779\n",
      "episode 284, reward 3.0, memory_length 2000, epsilon 0.75191, explore count:99, exploit count:32,time: 9.866\n",
      "episode 285, reward -142.0, memory_length 2000, epsilon 0.75116, explore count:102, exploit count:24,time: 9.442\n",
      "episode 286, reward 0.0, memory_length 2000, epsilon 0.7504, explore count:95, exploit count:26,time: 9.161\n",
      "episode 287, reward -86.0, memory_length 2000, epsilon 0.74965, explore count:94, exploit count:34,time: 9.818\n",
      "episode 288, reward 15.0, memory_length 2000, epsilon 0.7489, explore count:97, exploit count:44,time: 10.842\n",
      "episode 289, reward -186.0, memory_length 2000, epsilon 0.74816, explore count:87, exploit count:26,time: 8.574\n",
      "episode 290, reward -221.0, memory_length 2000, epsilon 0.74741, explore count:102, exploit count:37,time: 10.629\n",
      "episode 291, reward -401.0, memory_length 2000, epsilon 0.74666, explore count:90, exploit count:32,time: 9.349\n",
      "episode 292, reward -187.0, memory_length 2000, epsilon 0.74591, explore count:89, exploit count:36,time: 9.531\n",
      "episode 293, reward -230.0, memory_length 2000, epsilon 0.74517, explore count:90, exploit count:32,time: 9.35\n",
      "episode 294, reward -42.0, memory_length 2000, epsilon 0.74442, explore count:95, exploit count:26,time: 9.135\n",
      "episode 295, reward -213.0, memory_length 2000, epsilon 0.74368, explore count:107, exploit count:27,time: 9.958\n",
      "episode 296, reward -268.0, memory_length 2000, epsilon 0.74293, explore count:100, exploit count:38,time: 10.662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 297, reward -93.0, memory_length 2000, epsilon 0.74219, explore count:111, exploit count:40,time: 11.58\n",
      "episode 298, reward -252.0, memory_length 2000, epsilon 0.74145, explore count:98, exploit count:31,time: 9.828\n",
      "episode 299, reward -419.0, memory_length 2000, epsilon 0.74071, explore count:84, exploit count:46,time: 10.24\n",
      "episode 300, reward -95.0, memory_length 2000, epsilon 0.73997, explore count:100, exploit count:34,time: 10.047\n",
      "episode 301, reward 239.0, memory_length 2000, epsilon 0.73923, explore count:88, exploit count:30,time: 8.981\n",
      "episode 302, reward -187.0, memory_length 2000, epsilon 0.73849, explore count:98, exploit count:27,time: 9.415\n",
      "episode 303, reward -145.0, memory_length 2000, epsilon 0.73775, explore count:90, exploit count:19,time: 8.034\n",
      "episode 304, reward 63.0, memory_length 2000, epsilon 0.73701, explore count:89, exploit count:29,time: 8.984\n",
      "episode 305, reward 9.0, memory_length 2000, epsilon 0.73627, explore count:111, exploit count:53,time: 12.782\n",
      "episode 306, reward -470.0, memory_length 2000, epsilon 0.73554, explore count:85, exploit count:37,time: 9.448\n",
      "episode 307, reward -218.0, memory_length 2000, epsilon 0.7348, explore count:106, exploit count:21,time: 9.471\n",
      "episode 308, reward -315.0, memory_length 2000, epsilon 0.73407, explore count:106, exploit count:33,time: 10.469\n",
      "episode 309, reward -388.0, memory_length 2000, epsilon 0.73333, explore count:98, exploit count:45,time: 11.133\n",
      "episode 310, reward 90.0, memory_length 2000, epsilon 0.7326, explore count:94, exploit count:36,time: 9.997\n",
      "episode 311, reward -7.0, memory_length 2000, epsilon 0.73187, explore count:99, exploit count:34,time: 10.171\n",
      "episode 312, reward -320.0, memory_length 2000, epsilon 0.73114, explore count:102, exploit count:30,time: 9.992\n",
      "episode 313, reward -104.0, memory_length 2000, epsilon 0.7304, explore count:93, exploit count:35,time: 9.699\n",
      "episode 314, reward -109.0, memory_length 2000, epsilon 0.72967, explore count:94, exploit count:36,time: 10.004\n",
      "episode 315, reward -265.0, memory_length 2000, epsilon 0.72894, explore count:91, exploit count:32,time: 9.417\n",
      "episode 316, reward 68.0, memory_length 2000, epsilon 0.72822, explore count:107, exploit count:25,time: 9.857\n",
      "episode 317, reward -153.0, memory_length 2000, epsilon 0.72749, explore count:89, exploit count:41,time: 9.964\n",
      "episode 318, reward -181.0, memory_length 2000, epsilon 0.72676, explore count:101, exploit count:34,time: 10.275\n",
      "episode 319, reward 117.0, memory_length 2000, epsilon 0.72603, explore count:99, exploit count:30,time: 9.779\n",
      "episode 320, reward -329.0, memory_length 2000, epsilon 0.72531, explore count:90, exploit count:37,time: 9.877\n",
      "episode 321, reward -278.0, memory_length 2000, epsilon 0.72458, explore count:90, exploit count:51,time: 11.072\n",
      "episode 322, reward 145.0, memory_length 2000, epsilon 0.72386, explore count:100, exploit count:31,time: 9.902\n",
      "episode 323, reward -548.0, memory_length 2000, epsilon 0.72313, explore count:100, exploit count:33,time: 10.154\n",
      "episode 324, reward -309.0, memory_length 2000, epsilon 0.72241, explore count:91, exploit count:35,time: 9.723\n",
      "episode 325, reward -244.0, memory_length 2000, epsilon 0.72169, explore count:94, exploit count:45,time: 10.895\n",
      "episode 326, reward -367.0, memory_length 2000, epsilon 0.72097, explore count:103, exploit count:41,time: 10.997\n",
      "episode 327, reward -151.0, memory_length 2000, epsilon 0.72024, explore count:98, exploit count:40,time: 10.675\n",
      "episode 328, reward -383.0, memory_length 2000, epsilon 0.71952, explore count:98, exploit count:31,time: 9.808\n",
      "episode 329, reward -154.0, memory_length 2000, epsilon 0.71881, explore count:97, exploit count:36,time: 10.221\n",
      "episode 330, reward -302.0, memory_length 2000, epsilon 0.71809, explore count:99, exploit count:38,time: 10.578\n",
      "episode 331, reward 54.0, memory_length 2000, epsilon 0.71737, explore count:101, exploit count:34,time: 10.35\n",
      "episode 332, reward 187.0, memory_length 2000, epsilon 0.71665, explore count:90, exploit count:40,time: 10.126\n",
      "episode 333, reward -126.0, memory_length 2000, epsilon 0.71593, explore count:87, exploit count:40,time: 9.949\n",
      "episode 334, reward -269.0, memory_length 2000, epsilon 0.71522, explore count:98, exploit count:20,time: 8.806\n",
      "episode 335, reward -340.0, memory_length 2000, epsilon 0.7145, explore count:100, exploit count:36,time: 10.255\n",
      "episode 336, reward -162.0, memory_length 2000, epsilon 0.71379, explore count:97, exploit count:45,time: 11.057\n",
      "episode 337, reward -135.0, memory_length 2000, epsilon 0.71307, explore count:97, exploit count:32,time: 9.848\n",
      "episode 338, reward -167.0, memory_length 2000, epsilon 0.71236, explore count:108, exploit count:30,time: 10.418\n",
      "episode 339, reward -293.0, memory_length 2000, epsilon 0.71165, explore count:109, exploit count:34,time: 10.905\n",
      "episode 340, reward -43.0, memory_length 2000, epsilon 0.71094, explore count:91, exploit count:33,time: 9.4\n",
      "episode 341, reward -288.0, memory_length 2000, epsilon 0.71023, explore count:97, exploit count:38,time: 10.382\n",
      "episode 342, reward -208.0, memory_length 2000, epsilon 0.70952, explore count:96, exploit count:39,time: 10.416\n",
      "episode 343, reward -142.0, memory_length 2000, epsilon 0.70881, explore count:102, exploit count:29,time: 9.933\n",
      "episode 344, reward -14.0, memory_length 2000, epsilon 0.7081, explore count:96, exploit count:45,time: 11.073\n",
      "episode 345, reward -104.0, memory_length 2000, epsilon 0.70739, explore count:101, exploit count:54,time: 12.087\n",
      "episode 346, reward 157.0, memory_length 2000, epsilon 0.70668, explore count:103, exploit count:32,time: 10.239\n",
      "episode 347, reward -536.0, memory_length 2000, epsilon 0.70598, explore count:86, exploit count:35,time: 9.345\n",
      "episode 348, reward -426.0, memory_length 2000, epsilon 0.70527, explore count:100, exploit count:25,time: 9.416\n",
      "episode 349, reward -183.0, memory_length 2000, epsilon 0.70456, explore count:85, exploit count:40,time: 9.68\n",
      "episode 350, reward -192.0, memory_length 2000, epsilon 0.70386, explore count:92, exploit count:38,time: 10.046\n",
      "episode 351, reward -351.0, memory_length 2000, epsilon 0.70316, explore count:90, exploit count:49,time: 10.976\n",
      "episode 352, reward -104.0, memory_length 2000, epsilon 0.70245, explore count:85, exploit count:47,time: 10.364\n",
      "episode 353, reward -288.0, memory_length 2000, epsilon 0.70175, explore count:86, exploit count:38,time: 9.627\n",
      "episode 354, reward -54.0, memory_length 2000, epsilon 0.70105, explore count:97, exploit count:51,time: 11.508\n",
      "episode 355, reward -196.0, memory_length 2000, epsilon 0.70035, explore count:92, exploit count:34,time: 9.75\n",
      "episode 356, reward -545.0, memory_length 2000, epsilon 0.69965, explore count:85, exploit count:52,time: 10.903\n",
      "episode 357, reward -68.0, memory_length 2000, epsilon 0.69895, explore count:90, exploit count:43,time: 10.381\n",
      "episode 358, reward -62.0, memory_length 2000, epsilon 0.69825, explore count:85, exploit count:46,time: 10.339\n",
      "episode 359, reward -419.0, memory_length 2000, epsilon 0.69755, explore count:89, exploit count:35,time: 9.459\n",
      "episode 360, reward -414.0, memory_length 2000, epsilon 0.69685, explore count:85, exploit count:33,time: 9.097\n",
      "episode 361, reward -61.0, memory_length 2000, epsilon 0.69616, explore count:108, exploit count:37,time: 11.156\n",
      "episode 362, reward -15.0, memory_length 2000, epsilon 0.69546, explore count:102, exploit count:44,time: 11.274\n",
      "episode 363, reward -144.0, memory_length 2000, epsilon 0.69476, explore count:88, exploit count:31,time: 9.002\n",
      "episode 364, reward -402.0, memory_length 2000, epsilon 0.69407, explore count:90, exploit count:52,time: 11.204\n",
      "episode 365, reward -273.0, memory_length 2000, epsilon 0.69338, explore count:88, exploit count:40,time: 9.962\n",
      "episode 366, reward -48.0, memory_length 2000, epsilon 0.69268, explore count:87, exploit count:41,time: 10.003\n",
      "episode 367, reward 67.0, memory_length 2000, epsilon 0.69199, explore count:94, exploit count:39,time: 10.303\n",
      "episode 368, reward -402.0, memory_length 2000, epsilon 0.6913, explore count:91, exploit count:35,time: 9.547\n",
      "episode 369, reward -161.0, memory_length 2000, epsilon 0.69061, explore count:99, exploit count:38,time: 10.534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 370, reward -86.0, memory_length 2000, epsilon 0.68992, explore count:99, exploit count:48,time: 11.447\n",
      "episode 371, reward -154.0, memory_length 2000, epsilon 0.68923, explore count:90, exploit count:34,time: 9.53\n",
      "episode 372, reward -238.0, memory_length 2000, epsilon 0.68854, explore count:82, exploit count:36,time: 9.166\n",
      "episode 373, reward -68.0, memory_length 2000, epsilon 0.68785, explore count:91, exploit count:53,time: 11.258\n",
      "episode 374, reward -288.0, memory_length 2000, epsilon 0.68716, explore count:100, exploit count:47,time: 11.48\n",
      "episode 375, reward -36.0, memory_length 2000, epsilon 0.68647, explore count:93, exploit count:43,time: 10.586\n",
      "episode 376, reward -109.0, memory_length 2000, epsilon 0.68579, explore count:83, exploit count:50,time: 10.56\n",
      "episode 377, reward -253.0, memory_length 2000, epsilon 0.6851, explore count:91, exploit count:45,time: 10.63\n",
      "episode 378, reward -208.0, memory_length 2000, epsilon 0.68442, explore count:89, exploit count:36,time: 9.535\n",
      "episode 379, reward -162.0, memory_length 2000, epsilon 0.68373, explore count:91, exploit count:37,time: 9.816\n",
      "episode 380, reward -171.0, memory_length 2000, epsilon 0.68305, explore count:92, exploit count:47,time: 10.9\n",
      "episode 381, reward -338.0, memory_length 2000, epsilon 0.68236, explore count:87, exploit count:46,time: 10.455\n",
      "episode 382, reward -177.0, memory_length 2000, epsilon 0.68168, explore count:86, exploit count:56,time: 11.364\n",
      "episode 383, reward -343.0, memory_length 2000, epsilon 0.681, explore count:98, exploit count:37,time: 10.441\n",
      "episode 384, reward 111.0, memory_length 2000, epsilon 0.68032, explore count:82, exploit count:47,time: 10.08\n",
      "episode 385, reward -16.0, memory_length 2000, epsilon 0.67964, explore count:99, exploit count:44,time: 11.121\n",
      "episode 386, reward 36.0, memory_length 2000, epsilon 0.67896, explore count:108, exploit count:39,time: 11.305\n",
      "episode 387, reward 73.0, memory_length 2000, epsilon 0.67828, explore count:100, exploit count:47,time: 11.482\n",
      "episode 388, reward -212.0, memory_length 2000, epsilon 0.6776, explore count:79, exploit count:37,time: 9.069\n",
      "episode 389, reward -239.0, memory_length 2000, epsilon 0.67692, explore count:99, exploit count:35,time: 10.092\n",
      "episode 390, reward -297.0, memory_length 2000, epsilon 0.67625, explore count:86, exploit count:41,time: 9.935\n",
      "episode 391, reward -311.0, memory_length 2000, epsilon 0.67557, explore count:86, exploit count:38,time: 9.701\n",
      "episode 392, reward -214.0, memory_length 2000, epsilon 0.6749, explore count:91, exploit count:46,time: 10.751\n",
      "episode 393, reward -322.0, memory_length 2000, epsilon 0.67422, explore count:91, exploit count:45,time: 10.633\n",
      "episode 394, reward -90.0, memory_length 2000, epsilon 0.67355, explore count:98, exploit count:50,time: 11.475\n",
      "episode 395, reward -109.0, memory_length 2000, epsilon 0.67287, explore count:99, exploit count:40,time: 10.729\n",
      "episode 396, reward -64.0, memory_length 2000, epsilon 0.6722, explore count:105, exploit count:47,time: 11.763\n",
      "episode 397, reward -252.0, memory_length 2000, epsilon 0.67153, explore count:85, exploit count:58,time: 11.44\n",
      "episode 398, reward -288.0, memory_length 2000, epsilon 0.67086, explore count:84, exploit count:39,time: 9.599\n",
      "episode 399, reward -84.0, memory_length 2000, epsilon 0.67019, explore count:97, exploit count:51,time: 11.614\n",
      "episode 400, reward -154.0, memory_length 2000, epsilon 0.66952, explore count:93, exploit count:51,time: 11.367\n",
      "episode 401, reward -195.0, memory_length 2000, epsilon 0.66885, explore count:90, exploit count:49,time: 10.85\n",
      "episode 402, reward -387.0, memory_length 2000, epsilon 0.66818, explore count:82, exploit count:44,time: 9.949\n",
      "episode 403, reward -126.0, memory_length 2000, epsilon 0.66751, explore count:73, exploit count:57,time: 10.499\n",
      "episode 404, reward -99.0, memory_length 2000, epsilon 0.66684, explore count:98, exploit count:44,time: 10.854\n",
      "episode 405, reward -5.0, memory_length 2000, epsilon 0.66617, explore count:102, exploit count:47,time: 11.52\n",
      "episode 406, reward 18.0, memory_length 2000, epsilon 0.66551, explore count:89, exploit count:56,time: 11.561\n",
      "episode 407, reward -383.0, memory_length 2000, epsilon 0.66484, explore count:84, exploit count:51,time: 10.584\n",
      "episode 408, reward -503.0, memory_length 2000, epsilon 0.66418, explore count:92, exploit count:52,time: 11.363\n",
      "episode 409, reward -79.0, memory_length 2000, epsilon 0.66351, explore count:77, exploit count:50,time: 10.182\n",
      "episode 410, reward -19.0, memory_length 2000, epsilon 0.66285, explore count:96, exploit count:48,time: 11.28\n",
      "episode 411, reward -46.0, memory_length 2000, epsilon 0.66219, explore count:83, exploit count:56,time: 11.108\n",
      "episode 412, reward -54.0, memory_length 2000, epsilon 0.66153, explore count:77, exploit count:54,time: 10.614\n",
      "episode 413, reward -345.0, memory_length 2000, epsilon 0.66086, explore count:86, exploit count:40,time: 9.715\n",
      "episode 414, reward -194.0, memory_length 2000, epsilon 0.6602, explore count:92, exploit count:49,time: 11.11\n",
      "episode 415, reward -360.0, memory_length 2000, epsilon 0.65954, explore count:93, exploit count:52,time: 11.462\n",
      "episode 416, reward 35.0, memory_length 2000, epsilon 0.65888, explore count:95, exploit count:45,time: 10.908\n",
      "episode 417, reward -330.0, memory_length 2000, epsilon 0.65822, explore count:91, exploit count:37,time: 9.934\n",
      "episode 418, reward -163.0, memory_length 2000, epsilon 0.65757, explore count:97, exploit count:42,time: 10.78\n",
      "episode 419, reward -3.0, memory_length 2000, epsilon 0.65691, explore count:90, exploit count:42,time: 10.135\n",
      "episode 420, reward -216.0, memory_length 2000, epsilon 0.65625, explore count:98, exploit count:49,time: 11.532\n",
      "episode 421, reward -234.0, memory_length 2000, epsilon 0.6556, explore count:92, exploit count:51,time: 11.268\n",
      "episode 422, reward -608.0, memory_length 2000, epsilon 0.65494, explore count:88, exploit count:46,time: 10.538\n",
      "episode 423, reward -289.0, memory_length 2000, epsilon 0.65429, explore count:87, exploit count:53,time: 11.218\n",
      "episode 424, reward -324.0, memory_length 2000, epsilon 0.65363, explore count:90, exploit count:43,time: 10.246\n",
      "episode 425, reward -313.0, memory_length 2000, epsilon 0.65298, explore count:73, exploit count:42,time: 9.118\n",
      "episode 426, reward -73.0, memory_length 2000, epsilon 0.65232, explore count:91, exploit count:40,time: 10.163\n",
      "episode 427, reward -230.0, memory_length 2000, epsilon 0.65167, explore count:88, exploit count:41,time: 10.072\n",
      "episode 428, reward -339.0, memory_length 2000, epsilon 0.65102, explore count:88, exploit count:51,time: 10.954\n",
      "episode 429, reward -9.0, memory_length 2000, epsilon 0.65037, explore count:88, exploit count:38,time: 9.675\n",
      "episode 430, reward -77.0, memory_length 2000, epsilon 0.64972, explore count:81, exploit count:51,time: 10.507\n",
      "episode 431, reward -333.0, memory_length 2000, epsilon 0.64907, explore count:89, exploit count:41,time: 10.129\n",
      "episode 432, reward -14.0, memory_length 2000, epsilon 0.64842, explore count:105, exploit count:53,time: 12.364\n",
      "episode 433, reward -82.0, memory_length 2000, epsilon 0.64777, explore count:81, exploit count:57,time: 11.073\n",
      "episode 434, reward -405.0, memory_length 2000, epsilon 0.64712, explore count:94, exploit count:46,time: 10.951\n",
      "episode 435, reward -439.0, memory_length 2000, epsilon 0.64648, explore count:97, exploit count:37,time: 10.228\n",
      "episode 436, reward -108.0, memory_length 2000, epsilon 0.64583, explore count:93, exploit count:61,time: 12.339\n",
      "episode 437, reward -207.0, memory_length 2000, epsilon 0.64518, explore count:94, exploit count:45,time: 10.846\n",
      "episode 438, reward -186.0, memory_length 2000, epsilon 0.64454, explore count:86, exploit count:51,time: 10.88\n",
      "episode 439, reward -221.0, memory_length 2000, epsilon 0.64389, explore count:94, exploit count:41,time: 10.499\n",
      "episode 440, reward -234.0, memory_length 2000, epsilon 0.64325, explore count:98, exploit count:67,time: 13.242\n",
      "episode 441, reward -14.0, memory_length 2000, epsilon 0.64261, explore count:105, exploit count:54,time: 12.405\n",
      "episode 442, reward -276.0, memory_length 2000, epsilon 0.64196, explore count:90, exploit count:55,time: 11.525\n",
      "episode 443, reward 248.0, memory_length 2000, epsilon 0.64132, explore count:97, exploit count:40,time: 10.475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 444, reward -275.0, memory_length 2000, epsilon 0.64068, explore count:88, exploit count:46,time: 10.547\n",
      "episode 445, reward -347.0, memory_length 2000, epsilon 0.64004, explore count:97, exploit count:67,time: 13.244\n",
      "episode 446, reward -136.0, memory_length 2000, epsilon 0.6394, explore count:93, exploit count:46,time: 10.955\n",
      "episode 447, reward 4.0, memory_length 2000, epsilon 0.63876, explore count:82, exploit count:55,time: 10.922\n",
      "episode 448, reward -225.0, memory_length 2000, epsilon 0.63812, explore count:98, exploit count:54,time: 11.977\n",
      "episode 449, reward -187.0, memory_length 2000, epsilon 0.63748, explore count:90, exploit count:47,time: 10.718\n",
      "episode 450, reward -302.0, memory_length 2000, epsilon 0.63685, explore count:89, exploit count:56,time: 11.579\n",
      "episode 451, reward -415.0, memory_length 2000, epsilon 0.63621, explore count:91, exploit count:64,time: 12.487\n",
      "episode 452, reward -121.0, memory_length 2000, epsilon 0.63557, explore count:84, exploit count:40,time: 9.495\n",
      "episode 453, reward 12.0, memory_length 2000, epsilon 0.63494, explore count:92, exploit count:42,time: 10.463\n",
      "episode 454, reward -356.0, memory_length 2000, epsilon 0.6343, explore count:73, exploit count:65,time: 11.287\n",
      "episode 455, reward -171.0, memory_length 2000, epsilon 0.63367, explore count:96, exploit count:32,time: 9.773\n",
      "episode 456, reward -379.0, memory_length 2000, epsilon 0.63304, explore count:82, exploit count:62,time: 11.661\n",
      "episode 457, reward -207.0, memory_length 2000, epsilon 0.6324, explore count:89, exploit count:33,time: 9.28\n",
      "episode 458, reward -219.0, memory_length 2000, epsilon 0.63177, explore count:85, exploit count:51,time: 10.751\n",
      "episode 459, reward -275.0, memory_length 2000, epsilon 0.63114, explore count:108, exploit count:34,time: 10.785\n",
      "episode 460, reward -243.0, memory_length 2000, epsilon 0.63051, explore count:92, exploit count:55,time: 11.648\n",
      "episode 461, reward -38.0, memory_length 2000, epsilon 0.62988, explore count:88, exploit count:41,time: 10.051\n",
      "episode 462, reward -59.0, memory_length 2000, epsilon 0.62925, explore count:92, exploit count:60,time: 12.193\n",
      "episode 463, reward -26.0, memory_length 2000, epsilon 0.62862, explore count:95, exploit count:46,time: 10.874\n",
      "episode 464, reward -127.0, memory_length 2000, epsilon 0.62799, explore count:104, exploit count:62,time: 13.145\n",
      "episode 465, reward -171.0, memory_length 2000, epsilon 0.62736, explore count:83, exploit count:55,time: 11.04\n",
      "episode 466, reward -86.0, memory_length 2000, epsilon 0.62673, explore count:88, exploit count:58,time: 11.7\n",
      "episode 467, reward -225.0, memory_length 2000, epsilon 0.62611, explore count:78, exploit count:61,time: 11.365\n",
      "episode 468, reward -231.0, memory_length 2000, epsilon 0.62548, explore count:87, exploit count:41,time: 9.981\n",
      "episode 469, reward -383.0, memory_length 2000, epsilon 0.62486, explore count:85, exploit count:57,time: 11.317\n",
      "episode 470, reward -222.0, memory_length 2000, epsilon 0.62423, explore count:86, exploit count:40,time: 9.698\n",
      "episode 471, reward -198.0, memory_length 2000, epsilon 0.62361, explore count:87, exploit count:54,time: 11.174\n",
      "episode 472, reward -63.0, memory_length 2000, epsilon 0.62298, explore count:86, exploit count:54,time: 11.211\n",
      "episode 473, reward -81.0, memory_length 2000, epsilon 0.62236, explore count:86, exploit count:65,time: 12.147\n",
      "episode 474, reward -159.0, memory_length 2000, epsilon 0.62174, explore count:102, exploit count:57,time: 12.455\n",
      "episode 475, reward -244.0, memory_length 2000, epsilon 0.62112, explore count:95, exploit count:51,time: 11.456\n",
      "episode 476, reward -206.0, memory_length 2000, epsilon 0.62049, explore count:94, exploit count:64,time: 12.634\n",
      "episode 477, reward -379.0, memory_length 2000, epsilon 0.61987, explore count:89, exploit count:77,time: 13.637\n",
      "episode 478, reward -176.0, memory_length 2000, epsilon 0.61925, explore count:89, exploit count:63,time: 12.185\n",
      "episode 479, reward 22.0, memory_length 2000, epsilon 0.61863, explore count:83, exploit count:47,time: 10.256\n",
      "episode 480, reward -45.0, memory_length 2000, epsilon 0.61802, explore count:95, exploit count:60,time: 12.325\n",
      "episode 481, reward -145.0, memory_length 2000, epsilon 0.6174, explore count:93, exploit count:59,time: 11.952\n",
      "episode 482, reward -194.0, memory_length 2000, epsilon 0.61678, explore count:91, exploit count:61,time: 12.185\n",
      "episode 483, reward -434.0, memory_length 2000, epsilon 0.61616, explore count:88, exploit count:59,time: 11.807\n",
      "episode 484, reward 2.0, memory_length 2000, epsilon 0.61555, explore count:91, exploit count:48,time: 10.911\n",
      "episode 485, reward 139.0, memory_length 2000, epsilon 0.61493, explore count:93, exploit count:62,time: 12.372\n",
      "episode 486, reward -167.0, memory_length 2000, epsilon 0.61432, explore count:86, exploit count:44,time: 10.216\n",
      "episode 487, reward -65.0, memory_length 2000, epsilon 0.6137, explore count:91, exploit count:38,time: 9.973\n",
      "episode 488, reward -375.0, memory_length 2000, epsilon 0.61309, explore count:86, exploit count:45,time: 10.171\n",
      "episode 489, reward -88.0, memory_length 2000, epsilon 0.61248, explore count:82, exploit count:66,time: 11.977\n",
      "episode 490, reward -158.0, memory_length 2000, epsilon 0.61186, explore count:90, exploit count:54,time: 11.437\n",
      "episode 491, reward -320.0, memory_length 2000, epsilon 0.61125, explore count:75, exploit count:64,time: 11.397\n",
      "episode 492, reward -360.0, memory_length 2000, epsilon 0.61064, explore count:88, exploit count:48,time: 10.71\n",
      "episode 493, reward -428.0, memory_length 2000, epsilon 0.61003, explore count:86, exploit count:62,time: 11.913\n",
      "episode 494, reward -132.0, memory_length 2000, epsilon 0.60942, explore count:81, exploit count:61,time: 11.452\n",
      "episode 495, reward -168.0, memory_length 2000, epsilon 0.60881, explore count:78, exploit count:61,time: 11.234\n",
      "episode 496, reward -203.0, memory_length 2000, epsilon 0.6082, explore count:82, exploit count:63,time: 11.594\n",
      "episode 497, reward -585.0, memory_length 2000, epsilon 0.60759, explore count:85, exploit count:57,time: 11.226\n",
      "episode 498, reward -306.0, memory_length 2000, epsilon 0.60699, explore count:92, exploit count:42,time: 10.347\n",
      "episode 499, reward -333.0, memory_length 2000, epsilon 0.60638, explore count:101, exploit count:55,time: 12.283\n",
      "episode 500, reward -562.0, memory_length 2000, epsilon 0.60577, explore count:87, exploit count:46,time: 10.455\n",
      "episode 501, reward 72.0, memory_length 2000, epsilon 0.60517, explore count:97, exploit count:57,time: 12.148\n",
      "episode 502, reward -54.0, memory_length 2000, epsilon 0.60456, explore count:86, exploit count:53,time: 11.075\n",
      "episode 503, reward -392.0, memory_length 2000, epsilon 0.60396, explore count:92, exploit count:49,time: 11.1\n",
      "episode 504, reward 7.0, memory_length 2000, epsilon 0.60335, explore count:86, exploit count:54,time: 11.043\n",
      "episode 505, reward -504.0, memory_length 2000, epsilon 0.60275, explore count:92, exploit count:46,time: 10.834\n",
      "episode 506, reward -266.0, memory_length 2000, epsilon 0.60215, explore count:96, exploit count:54,time: 11.834\n",
      "episode 507, reward -86.0, memory_length 2000, epsilon 0.60154, explore count:80, exploit count:67,time: 11.982\n",
      "episode 508, reward -55.0, memory_length 2000, epsilon 0.60094, explore count:98, exploit count:53,time: 11.874\n",
      "episode 509, reward -482.0, memory_length 2000, epsilon 0.60034, explore count:88, exploit count:62,time: 12.125\n",
      "episode 510, reward -324.0, memory_length 2000, epsilon 0.59974, explore count:87, exploit count:61,time: 11.82\n",
      "episode 511, reward -339.0, memory_length 2000, epsilon 0.59914, explore count:94, exploit count:70,time: 13.181\n",
      "episode 512, reward -360.0, memory_length 2000, epsilon 0.59854, explore count:91, exploit count:50,time: 11.116\n",
      "episode 513, reward -126.0, memory_length 2000, epsilon 0.59794, explore count:88, exploit count:57,time: 11.558\n",
      "episode 514, reward 54.0, memory_length 2000, epsilon 0.59735, explore count:83, exploit count:49,time: 10.308\n",
      "episode 515, reward -60.0, memory_length 2000, epsilon 0.59675, explore count:89, exploit count:66,time: 12.474\n",
      "episode 516, reward -20.0, memory_length 2000, epsilon 0.59615, explore count:90, exploit count:57,time: 11.707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 517, reward -446.0, memory_length 2000, epsilon 0.59556, explore count:70, exploit count:69,time: 11.465\n",
      "episode 518, reward -74.0, memory_length 2000, epsilon 0.59496, explore count:86, exploit count:65,time: 12.145\n",
      "episode 519, reward -131.0, memory_length 2000, epsilon 0.59437, explore count:100, exploit count:63,time: 13.032\n",
      "episode 520, reward -218.0, memory_length 2000, epsilon 0.59377, explore count:91, exploit count:59,time: 11.965\n",
      "episode 521, reward -313.0, memory_length 2000, epsilon 0.59318, explore count:87, exploit count:58,time: 11.548\n",
      "episode 522, reward -324.0, memory_length 2000, epsilon 0.59258, explore count:80, exploit count:69,time: 12.167\n",
      "episode 523, reward -61.0, memory_length 2000, epsilon 0.59199, explore count:92, exploit count:75,time: 13.513\n",
      "episode 524, reward -117.0, memory_length 2000, epsilon 0.5914, explore count:81, exploit count:58,time: 11.2\n",
      "episode 525, reward -185.0, memory_length 2000, epsilon 0.59081, explore count:98, exploit count:73,time: 13.77\n",
      "episode 526, reward -378.0, memory_length 2000, epsilon 0.59022, explore count:113, exploit count:82,time: 15.615\n",
      "episode 527, reward -382.0, memory_length 2000, epsilon 0.58963, explore count:108, exploit count:65,time: 13.693\n",
      "episode 528, reward -302.0, memory_length 2000, epsilon 0.58904, explore count:113, exploit count:77,time: 15.162\n",
      "episode 529, reward -468.0, memory_length 2000, epsilon 0.58845, explore count:100, exploit count:59,time: 12.597\n",
      "episode 530, reward -237.0, memory_length 2000, epsilon 0.58786, explore count:114, exploit count:68,time: 14.375\n",
      "episode 531, reward -351.0, memory_length 2000, epsilon 0.58727, explore count:100, exploit count:53,time: 12.035\n",
      "episode 532, reward -694.0, memory_length 2000, epsilon 0.58669, explore count:97, exploit count:81,time: 14.381\n",
      "episode 533, reward -441.0, memory_length 2000, epsilon 0.5861, explore count:109, exploit count:77,time: 14.893\n",
      "episode 534, reward -481.0, memory_length 2000, epsilon 0.58551, explore count:107, exploit count:74,time: 14.598\n",
      "episode 535, reward -392.0, memory_length 2000, epsilon 0.58493, explore count:102, exploit count:84,time: 15.079\n",
      "episode 536, reward -590.0, memory_length 2000, epsilon 0.58434, explore count:111, exploit count:87,time: 15.97\n",
      "episode 537, reward -1008.0, memory_length 2000, epsilon 0.58376, explore count:104, exploit count:78,time: 14.676\n",
      "episode 538, reward -432.0, memory_length 2000, epsilon 0.58317, explore count:107, exploit count:74,time: 14.481\n",
      "episode 539, reward -478.0, memory_length 2000, epsilon 0.58259, explore count:105, exploit count:85,time: 15.39\n",
      "episode 540, reward -635.0, memory_length 2000, epsilon 0.58201, explore count:104, exploit count:66,time: 13.512\n",
      "episode 541, reward -729.0, memory_length 2000, epsilon 0.58143, explore count:97, exploit count:75,time: 14.018\n",
      "episode 542, reward -360.0, memory_length 2000, epsilon 0.58084, explore count:113, exploit count:106,time: 18.044\n",
      "episode 543, reward -184.0, memory_length 2000, epsilon 0.58026, explore count:115, exploit count:98,time: 17.343\n",
      "episode 544, reward -252.0, memory_length 2000, epsilon 0.57968, explore count:112, exploit count:81,time: 15.489\n",
      "episode 545, reward -520.0, memory_length 2000, epsilon 0.5791, explore count:99, exploit count:70,time: 13.604\n",
      "episode 546, reward -547.0, memory_length 2000, epsilon 0.57852, explore count:104, exploit count:64,time: 13.313\n",
      "episode 547, reward -635.0, memory_length 2000, epsilon 0.57795, explore count:114, exploit count:77,time: 15.37\n",
      "episode 548, reward -345.0, memory_length 2000, epsilon 0.57737, explore count:105, exploit count:79,time: 14.772\n",
      "episode 549, reward -363.0, memory_length 2000, epsilon 0.57679, explore count:99, exploit count:76,time: 14.095\n",
      "episode 550, reward -360.0, memory_length 2000, epsilon 0.57621, explore count:105, exploit count:71,time: 14.121\n",
      "episode 551, reward -325.0, memory_length 2000, epsilon 0.57564, explore count:103, exploit count:69,time: 13.748\n",
      "episode 552, reward -403.0, memory_length 2000, epsilon 0.57506, explore count:106, exploit count:56,time: 12.723\n",
      "episode 553, reward -436.0, memory_length 2000, epsilon 0.57449, explore count:102, exploit count:82,time: 15.318\n",
      "episode 554, reward -387.0, memory_length 2000, epsilon 0.57391, explore count:108, exploit count:66,time: 14.028\n",
      "episode 555, reward -514.0, memory_length 2000, epsilon 0.57334, explore count:109, exploit count:77,time: 15.016\n",
      "episode 556, reward -435.0, memory_length 2000, epsilon 0.57277, explore count:99, exploit count:84,time: 14.857\n",
      "episode 557, reward -673.0, memory_length 2000, epsilon 0.57219, explore count:101, exploit count:76,time: 14.334\n",
      "episode 558, reward -591.0, memory_length 2000, epsilon 0.57162, explore count:112, exploit count:77,time: 15.107\n",
      "episode 559, reward -342.0, memory_length 2000, epsilon 0.57105, explore count:105, exploit count:93,time: 16.214\n",
      "episode 560, reward -495.0, memory_length 2000, epsilon 0.57048, explore count:95, exploit count:81,time: 14.459\n",
      "episode 561, reward -400.0, memory_length 2000, epsilon 0.56991, explore count:104, exploit count:70,time: 13.953\n",
      "episode 562, reward -774.0, memory_length 2000, epsilon 0.56934, explore count:99, exploit count:62,time: 12.794\n",
      "episode 563, reward -666.0, memory_length 2000, epsilon 0.56877, explore count:99, exploit count:89,time: 15.429\n",
      "episode 564, reward -549.0, memory_length 2000, epsilon 0.5682, explore count:107, exploit count:89,time: 15.889\n",
      "episode 565, reward -469.0, memory_length 2000, epsilon 0.56763, explore count:94, exploit count:85,time: 14.704\n",
      "episode 566, reward -361.0, memory_length 2000, epsilon 0.56706, explore count:109, exploit count:94,time: 16.505\n",
      "episode 567, reward -653.0, memory_length 2000, epsilon 0.5665, explore count:102, exploit count:92,time: 15.824\n",
      "episode 568, reward -612.0, memory_length 2000, epsilon 0.56593, explore count:108, exploit count:78,time: 14.921\n",
      "episode 569, reward -423.0, memory_length 2000, epsilon 0.56536, explore count:116, exploit count:77,time: 15.413\n",
      "episode 570, reward -774.0, memory_length 2000, epsilon 0.5648, explore count:106, exploit count:100,time: 17.061\n",
      "episode 571, reward -306.0, memory_length 2000, epsilon 0.56423, explore count:110, exploit count:80,time: 15.252\n",
      "episode 572, reward -201.0, memory_length 2000, epsilon 0.56367, explore count:106, exploit count:66,time: 13.719\n",
      "episode 573, reward -869.0, memory_length 2000, epsilon 0.56311, explore count:93, exploit count:99,time: 15.873\n",
      "episode 574, reward -678.0, memory_length 2000, epsilon 0.56254, explore count:108, exploit count:69,time: 14.153\n",
      "episode 575, reward -257.0, memory_length 2000, epsilon 0.56198, explore count:111, exploit count:71,time: 14.464\n",
      "episode 576, reward -394.0, memory_length 2000, epsilon 0.56142, explore count:111, exploit count:80,time: 15.363\n",
      "episode 577, reward -311.0, memory_length 2000, epsilon 0.56086, explore count:111, exploit count:89,time: 16.326\n",
      "episode 578, reward -567.0, memory_length 2000, epsilon 0.5603, explore count:117, exploit count:75,time: 15.272\n",
      "episode 579, reward -320.0, memory_length 2000, epsilon 0.55974, explore count:96, exploit count:74,time: 13.747\n",
      "episode 580, reward -280.0, memory_length 2000, epsilon 0.55918, explore count:103, exploit count:85,time: 15.257\n",
      "episode 581, reward -586.0, memory_length 2000, epsilon 0.55862, explore count:98, exploit count:72,time: 13.649\n",
      "episode 582, reward -468.0, memory_length 2000, epsilon 0.55806, explore count:109, exploit count:86,time: 15.75\n",
      "episode 583, reward -638.0, memory_length 2000, epsilon 0.5575, explore count:103, exploit count:82,time: 15.078\n",
      "episode 584, reward -383.0, memory_length 2000, epsilon 0.55694, explore count:98, exploit count:75,time: 14.035\n",
      "episode 585, reward -828.0, memory_length 2000, epsilon 0.55639, explore count:103, exploit count:88,time: 15.532\n",
      "episode 586, reward -711.0, memory_length 2000, epsilon 0.55583, explore count:106, exploit count:83,time: 15.262\n",
      "episode 587, reward -483.0, memory_length 2000, epsilon 0.55527, explore count:101, exploit count:92,time: 15.794\n",
      "episode 588, reward -513.0, memory_length 2000, epsilon 0.55472, explore count:104, exploit count:86,time: 15.465\n",
      "episode 589, reward -468.0, memory_length 2000, epsilon 0.55416, explore count:100, exploit count:75,time: 14.059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 590, reward -454.0, memory_length 2000, epsilon 0.55361, explore count:104, exploit count:90,time: 15.924\n",
      "episode 591, reward -450.0, memory_length 2000, epsilon 0.55306, explore count:102, exploit count:93,time: 15.923\n",
      "episode 592, reward -187.0, memory_length 2000, epsilon 0.5525, explore count:108, exploit count:83,time: 15.334\n",
      "episode 593, reward -720.0, memory_length 2000, epsilon 0.55195, explore count:105, exploit count:84,time: 15.396\n",
      "episode 594, reward -224.0, memory_length 2000, epsilon 0.5514, explore count:109, exploit count:74,time: 14.62\n",
      "episode 595, reward -425.0, memory_length 2000, epsilon 0.55085, explore count:94, exploit count:86,time: 14.804\n",
      "episode 596, reward -453.0, memory_length 2000, epsilon 0.5503, explore count:105, exploit count:69,time: 13.812\n",
      "episode 597, reward -679.0, memory_length 2000, epsilon 0.54975, explore count:105, exploit count:82,time: 15.055\n",
      "episode 598, reward -554.0, memory_length 2000, epsilon 0.5492, explore count:107, exploit count:109,time: 17.819\n",
      "episode 599, reward -345.0, memory_length 2000, epsilon 0.54865, explore count:91, exploit count:90,time: 14.919\n",
      "episode 600, reward -262.0, memory_length 2000, epsilon 0.5481, explore count:91, exploit count:70,time: 13.02\n",
      "episode 601, reward -582.0, memory_length 2000, epsilon 0.54755, explore count:93, exploit count:80,time: 14.19\n",
      "episode 602, reward -316.0, memory_length 2000, epsilon 0.547, explore count:113, exploit count:68,time: 14.331\n",
      "episode 603, reward -673.0, memory_length 2000, epsilon 0.54646, explore count:100, exploit count:100,time: 16.624\n",
      "episode 604, reward -650.0, memory_length 2000, epsilon 0.54591, explore count:111, exploit count:88,time: 16.094\n",
      "episode 605, reward -452.0, memory_length 2000, epsilon 0.54536, explore count:108, exploit count:87,time: 15.781\n",
      "episode 606, reward -509.0, memory_length 2000, epsilon 0.54482, explore count:98, exploit count:73,time: 13.73\n",
      "episode 607, reward -669.0, memory_length 2000, epsilon 0.54427, explore count:99, exploit count:93,time: 15.787\n",
      "episode 608, reward -300.0, memory_length 2000, epsilon 0.54373, explore count:106, exploit count:92,time: 16.229\n",
      "episode 609, reward -495.0, memory_length 2000, epsilon 0.54319, explore count:93, exploit count:79,time: 14.036\n",
      "episode 610, reward -426.0, memory_length 2000, epsilon 0.54264, explore count:103, exploit count:80,time: 14.842\n",
      "episode 611, reward -144.0, memory_length 2000, epsilon 0.5421, explore count:106, exploit count:84,time: 15.393\n",
      "episode 612, reward -279.0, memory_length 2000, epsilon 0.54156, explore count:100, exploit count:84,time: 14.897\n",
      "episode 613, reward -620.0, memory_length 2000, epsilon 0.54102, explore count:91, exploit count:81,time: 14.056\n",
      "episode 614, reward -325.0, memory_length 2000, epsilon 0.54047, explore count:103, exploit count:85,time: 15.229\n",
      "episode 615, reward -515.0, memory_length 2000, epsilon 0.53993, explore count:104, exploit count:87,time: 15.593\n",
      "episode 616, reward -458.0, memory_length 2000, epsilon 0.53939, explore count:101, exploit count:78,time: 14.492\n",
      "episode 617, reward -450.0, memory_length 2000, epsilon 0.53885, explore count:105, exploit count:98,time: 16.675\n",
      "episode 618, reward -590.0, memory_length 2000, epsilon 0.53832, explore count:96, exploit count:77,time: 14.0\n",
      "episode 619, reward -428.0, memory_length 2000, epsilon 0.53778, explore count:98, exploit count:89,time: 15.242\n",
      "episode 620, reward -405.0, memory_length 2000, epsilon 0.53724, explore count:108, exploit count:72,time: 14.306\n",
      "episode 621, reward -574.0, memory_length 2000, epsilon 0.5367, explore count:101, exploit count:93,time: 15.973\n",
      "episode 622, reward -565.0, memory_length 2000, epsilon 0.53617, explore count:97, exploit count:68,time: 13.2\n",
      "episode 623, reward -630.0, memory_length 2000, epsilon 0.53563, explore count:101, exploit count:84,time: 15.034\n",
      "episode 624, reward -270.0, memory_length 2000, epsilon 0.53509, explore count:99, exploit count:78,time: 14.25\n",
      "episode 625, reward -423.0, memory_length 2000, epsilon 0.53456, explore count:106, exploit count:103,time: 17.238\n",
      "episode 626, reward -369.0, memory_length 2000, epsilon 0.53402, explore count:94, exploit count:74,time: 13.525\n",
      "episode 627, reward -536.0, memory_length 2000, epsilon 0.53349, explore count:101, exploit count:78,time: 14.519\n",
      "episode 628, reward -446.0, memory_length 2000, epsilon 0.53296, explore count:109, exploit count:74,time: 14.599\n",
      "episode 629, reward -576.0, memory_length 2000, epsilon 0.53242, explore count:98, exploit count:116,time: 17.868\n",
      "episode 630, reward -653.0, memory_length 2000, epsilon 0.53189, explore count:110, exploit count:91,time: 16.217\n",
      "episode 631, reward -756.0, memory_length 2000, epsilon 0.53136, explore count:100, exploit count:87,time: 15.236\n",
      "episode 632, reward -425.0, memory_length 2000, epsilon 0.53083, explore count:102, exploit count:91,time: 15.729\n",
      "episode 633, reward -585.0, memory_length 2000, epsilon 0.5303, explore count:103, exploit count:90,time: 16.061\n",
      "episode 634, reward -189.0, memory_length 2000, epsilon 0.52977, explore count:106, exploit count:77,time: 14.769\n",
      "episode 635, reward -267.0, memory_length 2000, epsilon 0.52924, explore count:100, exploit count:87,time: 15.26\n",
      "episode 636, reward -577.0, memory_length 2000, epsilon 0.52871, explore count:94, exploit count:89,time: 16.031\n",
      "episode 637, reward -468.0, memory_length 2000, epsilon 0.52818, explore count:104, exploit count:98,time: 18.94\n",
      "episode 638, reward -549.0, memory_length 2000, epsilon 0.52765, explore count:100, exploit count:90,time: 16.666\n",
      "episode 639, reward -405.0, memory_length 2000, epsilon 0.52712, explore count:107, exploit count:101,time: 18.508\n",
      "episode 640, reward -399.0, memory_length 2000, epsilon 0.5266, explore count:112, exploit count:88,time: 16.617\n",
      "episode 641, reward -583.0, memory_length 2000, epsilon 0.52607, explore count:109, exploit count:85,time: 16.822\n",
      "episode 642, reward -606.0, memory_length 2000, epsilon 0.52554, explore count:99, exploit count:101,time: 18.109\n",
      "episode 643, reward -375.0, memory_length 2000, epsilon 0.52502, explore count:104, exploit count:95,time: 16.992\n",
      "episode 644, reward -310.0, memory_length 2000, epsilon 0.52449, explore count:109, exploit count:80,time: 15.625\n",
      "episode 645, reward -720.0, memory_length 2000, epsilon 0.52397, explore count:100, exploit count:108,time: 19.638\n",
      "episode 646, reward -684.0, memory_length 2000, epsilon 0.52344, explore count:90, exploit count:96,time: 15.712\n",
      "episode 647, reward -689.0, memory_length 2000, epsilon 0.52292, explore count:101, exploit count:107,time: 17.351\n",
      "episode 648, reward -376.0, memory_length 2000, epsilon 0.5224, explore count:97, exploit count:85,time: 14.848\n",
      "episode 649, reward -752.0, memory_length 2000, epsilon 0.52188, explore count:103, exploit count:108,time: 17.64\n",
      "episode 650, reward -235.0, memory_length 2000, epsilon 0.52135, explore count:104, exploit count:72,time: 14.542\n",
      "episode 651, reward -347.0, memory_length 2000, epsilon 0.52083, explore count:110, exploit count:104,time: 19.405\n",
      "episode 652, reward -721.0, memory_length 2000, epsilon 0.52031, explore count:108, exploit count:115,time: 19.262\n",
      "episode 653, reward -954.0, memory_length 2000, epsilon 0.51979, explore count:96, exploit count:99,time: 17.58\n",
      "episode 654, reward -571.0, memory_length 2000, epsilon 0.51927, explore count:91, exploit count:122,time: 19.645\n",
      "episode 655, reward -443.0, memory_length 2000, epsilon 0.51875, explore count:97, exploit count:92,time: 18.927\n",
      "episode 656, reward -495.0, memory_length 2000, epsilon 0.51823, explore count:97, exploit count:94,time: 16.533\n",
      "episode 657, reward -730.0, memory_length 2000, epsilon 0.51772, explore count:94, exploit count:87,time: 15.231\n",
      "episode 658, reward -423.0, memory_length 2000, epsilon 0.5172, explore count:90, exploit count:89,time: 15.809\n",
      "episode 659, reward -486.0, memory_length 2000, epsilon 0.51668, explore count:107, exploit count:110,time: 19.803\n",
      "episode 660, reward -716.0, memory_length 2000, epsilon 0.51616, explore count:94, exploit count:102,time: 17.172\n",
      "episode 661, reward -663.0, memory_length 2000, epsilon 0.51565, explore count:104, exploit count:94,time: 16.768\n",
      "episode 662, reward -754.0, memory_length 2000, epsilon 0.51513, explore count:96, exploit count:104,time: 17.225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 663, reward -591.0, memory_length 2000, epsilon 0.51462, explore count:114, exploit count:78,time: 15.382\n",
      "episode 664, reward -569.0, memory_length 2000, epsilon 0.5141, explore count:95, exploit count:101,time: 17.489\n",
      "episode 665, reward -599.0, memory_length 2000, epsilon 0.51359, explore count:103, exploit count:104,time: 20.01\n",
      "episode 666, reward -482.0, memory_length 2000, epsilon 0.51307, explore count:106, exploit count:100,time: 18.887\n",
      "episode 667, reward -277.0, memory_length 2000, epsilon 0.51256, explore count:110, exploit count:78,time: 18.012\n",
      "episode 668, reward -309.0, memory_length 2000, epsilon 0.51205, explore count:94, exploit count:83,time: 14.73\n",
      "episode 669, reward -441.0, memory_length 2000, epsilon 0.51154, explore count:107, exploit count:92,time: 17.014\n",
      "episode 670, reward -495.0, memory_length 2000, epsilon 0.51103, explore count:97, exploit count:72,time: 14.538\n",
      "episode 671, reward -487.0, memory_length 2000, epsilon 0.51051, explore count:102, exploit count:93,time: 17.906\n",
      "episode 672, reward -864.0, memory_length 2000, epsilon 0.51, explore count:91, exploit count:97,time: 16.983\n",
      "episode 673, reward -485.0, memory_length 2000, epsilon 0.50949, explore count:101, exploit count:91,time: 15.898\n",
      "episode 674, reward -329.0, memory_length 2000, epsilon 0.50898, explore count:96, exploit count:61,time: 12.657\n",
      "episode 675, reward -318.0, memory_length 2000, epsilon 0.50848, explore count:98, exploit count:71,time: 13.96\n",
      "episode 676, reward -623.0, memory_length 2000, epsilon 0.50797, explore count:101, exploit count:102,time: 17.956\n",
      "episode 677, reward -646.0, memory_length 2000, epsilon 0.50746, explore count:101, exploit count:99,time: 16.774\n",
      "episode 678, reward -470.0, memory_length 2000, epsilon 0.50695, explore count:105, exploit count:89,time: 16.096\n",
      "episode 679, reward -450.0, memory_length 2000, epsilon 0.50644, explore count:101, exploit count:107,time: 17.349\n",
      "episode 680, reward -376.0, memory_length 2000, epsilon 0.50594, explore count:93, exploit count:99,time: 16.656\n",
      "episode 681, reward -673.0, memory_length 2000, epsilon 0.50543, explore count:98, exploit count:106,time: 19.83\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "#### simulation starts ####\n",
    "for episode in range(Episodes):\n",
    "    episode_start_time = time.time()\n",
    "    done = False\n",
    "    score = 0\n",
    "\n",
    "    # reset at the start of each episode\n",
    "    state = env.reset()\n",
    "\n",
    "    while not done:\n",
    "\n",
    "        # 1. Pick epsilon-greedy action from possible actions for the current state\n",
    "        action_idx = agent.get_action(state,episode)\n",
    "        action = env.action_space[action_idx]\n",
    "        # 2. Evaluate your reward and next state\n",
    "        next_state, reward, done = env.step(state, action, Time_matrix)\n",
    "            \n",
    "        #next_state, reward, done, info = env.step(action)\n",
    "\n",
    "        # 3. Append the experience to the memory\n",
    "        # save the sample <s, a, r, s', done> to the replay memory\n",
    "        agent.append_sample(state, action_idx, reward, next_state, done)\n",
    "\n",
    "        # 4. Train the model by calling function agent.train_model\n",
    "        agent.train_model()\n",
    "\n",
    "        # add reward to the total score of this episode\n",
    "        score += reward\n",
    "        state = next_state\n",
    "\n",
    "\n",
    "\n",
    "    # epsilon decay\n",
    "    if agent.epsilon > agent.epsilon_min:\n",
    "        agent.epsilon *= agent.epsilon_decay\n",
    "#         agent.epsilon = self.epsilon_min + (self.epsilon_max - self.epsilon_min) * np.exp(agent.epsilon_decay*episode)\n",
    "\n",
    "    # 5. Keep a track of rewards, Q-values, loss\n",
    "    # store total reward obtained in this episode\n",
    "    rewards_per_episode.append(score)\n",
    "    episodes.append(episode)\n",
    "    \n",
    "    # Save summary after every episode\n",
    "    explore_count, exploit_count = agent.get_summary_details()\n",
    "    episode_time = time.time() - episode_start_time\n",
    "    summary_df = update_summary_details(episode,score, len(agent.memory),round(agent.epsilon,5),explore_count, exploit_count,round(episode_time,3))\n",
    "    agent.reset_episode_counts()\n",
    "        \n",
    "    # every episode:\n",
    "    print(f\"episode {episode}, reward {score}, memory_length {len(agent.memory)}, epsilon {round(agent.epsilon,5)}, explore:{explore_count}, exploit:{exploit_count},time: {round(episode_time,3)}\")\n",
    "        \n",
    "    # every few episodes:\n",
    "    if episode % 1000 == 0:\n",
    "        # store q-values of some prespecified state-action pairs\n",
    "        # q_dict = agent.store_q_values()\n",
    "        \n",
    "        \n",
    "        curr_elapsed_time = time.time() - start_time\n",
    "        print(f'Episodes:{episode} - Elapsed_time:{round(curr_elapsed_time,3)} ')  \n",
    "\n",
    "        # save model weights\n",
    "        agent.save_model_weights(name=\"model_weights.h5\")\n",
    "\n",
    " \n",
    "# save model weights\n",
    "agent.save_model_weights(name=\"model_weights.h5\")\n",
    "    \n",
    "elapsed_time = time.time() - start_time\n",
    "print(f'Total elapsed_time:{elapsed_time}')       \n",
    "    \n",
    "        \n",
    "#### simulation complete ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-10-16T15:55:59.931Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(0, figsize=(16,8))\n",
    "plt.plot(summary_df[['EPISODE','REWARD']])\n",
    "plt.title('REWARDS PER EPISODE')\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Reward\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# save plots in saved_plots/ directory\n",
    "plt.savefig('rewards_episodes.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-10-16T15:55:59.934Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-10-16T15:55:59.936Z"
    }
   },
   "outputs": [],
   "source": [
    "# save stuff as pickle\n",
    "def save_pickle(obj, name):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# make directory\n",
    "if not os.path.exists(\"saved_pickle_files\"):\n",
    "    os.mkdir(\"saved_pickle_files\")\n",
    "\n",
    "# save rewards_per_episode\n",
    "save_pickle(rewards_per_episode, \"saved_pickle_files/rewards_per_episode\")\n",
    "save_pickle(summary_df, \"saved_pickle_files/summary_per_episode\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracking Convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-10-16T15:55:59.939Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# plot results\n",
    "with open('saved_pickle_files/summary_per_episode.pkl', 'rb') as f:\n",
    "    summary_data = pickle.load(f)\n",
    "\n",
    "    \n",
    "plt.figure(0, figsize=(16,8))\n",
    "plt.plot(summary_data[['EPISODE','REWARD']])\n",
    "plt.title('REWARDS PER EPISODE')\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Reward\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# save plots in saved_plots/ directory\n",
    "plt.savefig('rewards_episodes.png')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-10-16T15:55:59.941Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# plot results\n",
    "with open('saved_pickle_files/rewards_per_episode.pkl', 'rb') as f:\n",
    "    rewards_per_episode = pickle.load(f)\n",
    "\n",
    "plt.plot(list(range(len(rewards_per_episode))), rewards_per_episode)\n",
    "plt.xlabel(\"episode number\")\n",
    "plt.ylabel(\"reward per episode\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# save plots in saved_plots/ directory\n",
    "plt.savefig('rewards.png')\n",
    "\n",
    "\n",
    "print(\"Average reward of last 100 episodes is {0}\".format(np.mean(rewards_per_episode[-100:]))) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Plot exploration vs exploitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(0, figsize=(16,8))\n",
    "plt.plot(summary_data[['EXPLORE_CNT','EXPLOIT_CNT']])\n",
    "plt.title('EXPLORATION vs EXPLOITATION')\n",
    "plt.xlabel(\"Exploration\")\n",
    "plt.ylabel(\"Exploitation\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# save plots in saved_plots/ directory\n",
    "plt.savefig('exploration_exploitation.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Epsilon-decay sample function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Try building a similar epsilon-decay function for your model.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-10-16T15:55:59.946Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "max_epsilon = 1.0\n",
    "min_epsilon = 0.0000001\n",
    "episode_count = 25000\n",
    "exp_value = 1/10**(len(str(episode_count))-1)\n",
    "print(f'exp:{exp_value}')\n",
    "time = np.arange(0,episode_count)\n",
    "epsilon = []\n",
    "for i in range(0,episode_count):\n",
    "    epsilon.append(min_epsilon + (max_epsilon - min_epsilon) * np.exp(-exp_value*i))\n",
    "    \n",
    "\n",
    "plt.plot(time, epsilon)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-10-16T15:55:59.948Z"
    }
   },
   "outputs": [],
   "source": [
    "# From starter code\n",
    "total_episodes = 10000\n",
    "time = np.arange(0,total_episodes)\n",
    "epsilon = []\n",
    "for i in range(0,total_episodes):\n",
    "    epsilon.append(0 + (1 - 0) * np.exp(-0.0009*i))\n",
    "    \n",
    "plt.plot(time, epsilon)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-10-16T15:55:59.953Z"
    }
   },
   "outputs": [],
   "source": [
    "max_epsilon = 1.0\n",
    "min_epsilon = 0.001\n",
    "episode_count = 50\n",
    "exp_value = 1/10**(len(str(episode_count))-1)\n",
    "time = np.arange(0,episode_count)\n",
    "epsilon = []\n",
    "for i in range(0,episode_count):\n",
    "    epsilon.append(min_epsilon + (max_epsilon - min_epsilon) * np.exp(-exp_value*i))\n",
    "    \n",
    "\n",
    "plt.plot(time, epsilon)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "My Steps",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
